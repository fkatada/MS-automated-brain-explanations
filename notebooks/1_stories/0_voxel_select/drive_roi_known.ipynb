{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import imodelsx.util\n",
    "import sasc.viz\n",
    "import pickle as pkl\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import norm\n",
    "from sasc.config import CACHE_DIR, RESULTS_DIR, cache_ngrams_dir, regions_idxs_dir\n",
    "import sasc.modules.fmri_module\n",
    "ngrams_list = joblib.load(join(cache_ngrams_dir, 'fmri_UTS02_ngrams.pkl')) # ngrams are same for both models\n",
    "\n",
    "# subject = 'S02'\n",
    "subject = 'S03'\n",
    "rois_dict = joblib.load(join(regions_idxs_dir, f'rois_{subject}.jbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(rois_dict.keys())\n",
    "if subject == 'S03':\n",
    "    rois_dict['OPA'] = rois_dict['TOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions from embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs = joblib.load(join(cache_ngrams_dir, 'fmri_embs.pkl'))\n",
    "embs = joblib.load(join(cache_ngrams_dir, 'fmri_embs_llama.pkl'))\n",
    "mod = sasc.modules.fmri_module.fMRIModule(\n",
    "    subject=f\"UT{subject}\",\n",
    "    # checkpoint=\"facebook/opt-30b\",\n",
    "    checkpoint=\"huggyllama/llama-30b\",\n",
    "    init_model=False,\n",
    "    restrict_weights=False,\n",
    ")\n",
    "voxel_preds = mod(embs=embs, return_all=True)\n",
    "outputs_dict = {\n",
    "    k: voxel_preds[:, np.array(rois_dict[k])].mean(axis=1)\n",
    "    for k in rois_dict\n",
    "}\n",
    "joblib.dump(outputs_dict, join(\n",
    "    # cache_ngrams_dir, f'rois_ngram_outputs_dict_{subject}_opt.pkl'))\n",
    "    cache_ngrams_dir, f'rois_ngram_outputs_dict_{subject}_llama.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dict = joblib.load(\n",
    "    join(cache_ngrams_dir, f'rois_ngram_outputs_dict_{subject}_opt.pkl'))\n",
    "df_opt = pd.DataFrame(outputs_dict, index=ngrams_list)\n",
    "outputs_dict = joblib.load(\n",
    "    join(cache_ngrams_dir, f'rois_ngram_outputs_dict_{subject}_llama.pkl'))\n",
    "df_llama = pd.DataFrame(outputs_dict, index=ngrams_list)\n",
    "df = df_opt + df_llama\n",
    "ROIS_LOC = ['RSC', 'PPA', 'OPA']  # 'OPA', 'PPA']\n",
    "for k in ROIS_LOC:\n",
    "    df_opt[k + '_only'] = df_opt[k] - \\\n",
    "        df_opt[[c for c in ROIS_LOC if c != k]].mean(axis=1)\n",
    "    df_llama[k + '_only'] = df_llama[k] - \\\n",
    "        df_llama[[c for c in ROIS_LOC if c != k]].mean(axis=1)\n",
    "    df[k + '_only'] = df[k] - \\\n",
    "        df[[c for c in ROIS_LOC if c != k]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_scores = {\n",
    "    k: np.corrcoef(df_opt[k], df_llama[k])[0, 1]\n",
    "    for k in df.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascending = False  # should be false to get driving ngrams\n",
    "top_ngrams_dict = {}\n",
    "for k in df.columns:\n",
    "    top_ngrams_dict[k] = df.sort_values(\n",
    "        k, ascending=ascending).index[:100].tolist()\n",
    "    # if k in ROIS_LOC:\n",
    "\n",
    "    # top_ngrams_dict[k + '_only'] = df.sort_values(\n",
    "    # k + '_only', ascending=ascending).index[:100].tolist()\n",
    "top_ngrams_df = pd.DataFrame(top_ngrams_dict)\n",
    "top_ngrams_df.to_csv(f'top_ngrams_by_roi_{subject}.csv')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    rois = ['RSC', 'OPA', 'PPA', 'IPS', 'pSTS', 'sPMv',\n",
    "            'EBA', 'OFA'] + ['RSC_only', 'OPA_only', 'PPA_only']\n",
    "    rois = [r for r in rois if not r == 'pSTS']  # never localized pSTS in S03\n",
    "    display(top_ngrams_df[rois])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = imodelsx.llm.get_llm('gpt-4')  # -turbo-0125-spot')\n",
    "try:\n",
    "    explanations = json.load(\n",
    "        open(f'explanations_known_roi_{subject}.json', 'r'))\n",
    "except:\n",
    "    explanations = {}\n",
    "for k in top_ngrams_df.columns:\n",
    "\n",
    "    s = '- ' + '\\n- '.join(top_ngrams_df[k].iloc[:60])\n",
    "    prompt = f'''Here is a list of phrases:\n",
    "    {s}\n",
    "\n",
    "    What is a common theme among these phrases? Return only a concise phrase.'''\n",
    "    if not k in explanations:\n",
    "        explanations[k] = gpt4(prompt)\n",
    "json.dump(explanations, open(\n",
    "    f'explanations_by_roi_{subject}.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RSC': 'Movement and location',\n",
       " 'OPA': 'Descriptions of locations and directions',\n",
       " 'PPA': 'Locations and spaces',\n",
       " 'IPS': '\"Descriptions of locations and actions in a narrative context\"',\n",
       " 'sPMv': None,\n",
       " 'EBA': 'Physical contact or interaction',\n",
       " 'OFA': 'Narration of past events or experiences.',\n",
       " 'RSC_only': 'Locations and movement',\n",
       " 'OPA_only': 'Personal growth and emotional healing',\n",
       " 'PPA_only': 'Household items and personal belongings'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: explanations[k] for k in rois}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my trapper keeper', 'a garbage bag', 'placemats some crayons', 'on paper plates', 'that garbage bag', \"'re throwing napkins\", 'box of discarded', 'your worry beads', 'of wrapping paper', 'a fire hose', 'a business card', 'of sweatpants', \"'d grown napkins\", 'wrapped my napkin', 'in sugar jars', 'two room school', 'their chew toys', 'his flannel shirt', 'grabbed the trashbag', 'garbage bag', 'those plastic containers', 'his bathrobe', 'their cigarette wrappers', 'an overturned cardboard', 'socks and loafers', 'that beach towel', 'the air mattress', 'my bathrobe', 'our dishwasher', 'a bathrobe', 'the cough syrup', 'a stuffed animal', 'skivvies toothbrush floss', 'an air mattress', 'powerlifting cinder blocks', 'glasses of cheap', 'chew toys', 'of cheap beer', 'bath in bathrobes', 'a hospital bed', 'the tiny crumpled', 'throwing napkins', 'the laundry hamper', 'overturned cardboard box', 'like your shirt', 'wearing sweatpants', 'a trash can', 'milk bottle tops', 'was wearing sweatpants', 'fire hose', 'my stuffed animal', 'sad moving van', 'neon protest signs', 'his bike shoes', 'an index card', 'a sweat pants', 'knocking back cans', 'want a mcflurry', 'backyard wielded screwdrivers', 'in a bathrobe', 'stuffed animal', 'napkins', 'bring place mats', 'tiny crumpled', 'napkin', 'a checked suitcase', 'a ritalin drip', 'could fix tractors', 'sugar jars', 'the hospital blanket', 'see that jar', 'a sleeping bag', 'bought a couch', 'crawford wire hanger', 'their beach chairs', 'vomit smelling couch', 'moldy beach umbrellas', 'and my stapler', 'grabbed a comforter', 'boxed the towels', 'grown napkins', 'change a diaper', 'a paper airplane', 'the moving van', 'briefcase filled', 'my cheese sandwich', 'cases of beer', 'in something silky', 'a cheese sandwich', 'overpriced coffee shops', 'beach towel', 'white chef coat', 'some lighter fluid', 'salad and stale', 'worry beads', 'vomited a washpan', 'the copier room', 'these brown paper', 'the pay phone', 'off my bathrobe']\n"
     ]
    }
   ],
   "source": [
    "print(top_ngrams_df['PPA_only'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S03 Export selected rois to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_avoid_suffixes = {\n",
    "    'Numbers_only': ' Avoid mentioning any measurements or times.',\n",
    "    'Time_only': ' Avoid mentioning any numbers, measurements, or years. ',\n",
    "    'Years_only': ' Avoid mentioning any numbers, measurements, or times of day. (like \"three o\\'clock\" or \"hours\" or \"fifty\")',\n",
    "    'Measurements_only': ' Avoid mentioning any numbers or times. (like \"three o\\'clock\" or \"hours\" or \"fifty\")',\n",
    "\n",
    "    'Relationships_only': ' Avoid mentioning conversations or dialogue interactions between people.',\n",
    "    'Dialogue_only': ' Avoid mentioning the people involved in the conversation.',\n",
    "    'Introspection_only': 'Avoid mentioning conversations or dialogue interactions between people.',\n",
    "\n",
    "    'Gruesome': '',\n",
    "    'Clothing and Physical Appearance': '',\n",
    "    'Colors': '',\n",
    "\n",
    "    'Sexual_and_Romantic_Interactions': '',\n",
    "    'Secretive_Or_Covert_Actions': '',\n",
    "    'Recognition': '',\n",
    "\n",
    "    'Positive Emotional Reactions': '',\n",
    "    'Negative Emotional Reactions': '',\n",
    "    'Professions': '',\n",
    "    'Fear and Avoidance': '',\n",
    "\n",
    "    'EBA': ' Avoid mentioning any locations.',\n",
    "    'IPS': ' Avoid mentioning any locations.',\n",
    "    'OFA': ' Avoid mentioning any locations.',\n",
    "    'OPA': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'OPA_only': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'PPA': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'PPA_only': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'RSC': '',\n",
    "    'RSC_only': '',\n",
    "    'sPMv': ' Avoid mentioning any locations.'\n",
    "}\n",
    "\n",
    "top_ngrams_clean = {\n",
    "    'Numbers_only': ['five', 'twenty', 'three hundred', 'a million', 'forty six', 'ninety one'],\n",
    "    'Time_only': ['one o\\'clock', ],\n",
    "    'Years_only': ['of nineteen sixty', 'until nineteen sixty', 'until nineteen seventy', 'of nineteen ninety'],\n",
    "    'Measurements_only': ['two mile thick', 'eighty milligrams', 'two hundred gallons', 'several hundred cubic', 'eight thousand square', 'to fifty feet'],\n",
    "\n",
    "    'Relationships_only': ['brother and sister', 'he was a good friend', 'a wonderful uncle', 'just like her father', 'boyfriend', 'wife', 'aunt'],\n",
    "    'Dialogue_only': ['he said', 'she said', 'they whispered', 'he chimed in', '\"wow!\"', '\"hello\"', 'he shouted', 'she responded'],\n",
    "    'Introspection_only': ['he reflected', 'she thought back', 'they thought hard', \"hm that's interesting\", 'ah yes', 'thought carefully', 'full of introspection'],\n",
    "\n",
    "    'Gruesome': ['my scalp peeled', 'soaked with sweat', 'eyes were swollen', 'of skin peeled', 'legs were swollen', 'swollen and red', 'burned the skin', 'blood was trickling', 'skin was bubbling'],\n",
    "    'Clothing and Physical Appearance': ['in his beret', 'in a bathrobe', 'a red hoodie', 'blonde hair dangling', 'his flannel shirt', 'ancient blue hatchback', 'his tan uniform', 'was wearing black', 'wore flannel'],\n",
    "    'Colors': ['my black chevy', 'a bumpy orange', 'and frosty pink', 'of cornfields amber', 'bands of lavender'],\n",
    "\n",
    "    'Sexual_and_Romantic_Interactions': ['tried to flirt', 'me a blowjob', 'to get laid', 'satisfy me sexually', 'that my flirting', 'they applaud virginity', 'hitting on me', 'have sex so', 'grand romantic gesture', 'lost my virginity', 'have fucking groupies', 'a housewarming gift', 'had masturbated to', 'for hitting on', 'even had sex'],\n",
    "    'Secretive_Or_Covert_Actions': ['sneak out when', 'bribe the guards', 'of getting caught', 'to sneak out', 'sped off before', 'locked the door', 'she hung up', 'kept it hidden', 'she hanged up', \"'m not invited\", 'leaves the room', 'not tell anyone', 'could escape quietly'],\n",
    "    'Recognition': ['neighbor had recognized', 'officer heard me', 'friends saw me', 'knew exactly who', 'i provoked gasps', 'she recognized me', 'guard spotted us'],\n",
    "\n",
    "    'Positive Emotional Reactions': ['she started laughing', 'smiled and said', 'he giggled', 'they were happy to see it', 'she was relieved'],\n",
    "    'Negative Emotional Reactions': ['mom started crying', 'started to cry', 'eyed her suspiciously', 'annoyed him', 'they were upset'],\n",
    "    \"Professions\": ['his cop training', 'other egghead phds', 'parents were doctors', 'a gay speechwriter', 'a cambridge educated', 'i played college', 'been my accountant', 'my indian heritage', 'taught them japanese'],\n",
    "    \"Fear and Avoidance\": ['he screamed', 'always too scared', 'she steered clear', 'they ran away', 'constant fear', 'always afraid'],\n",
    "\n",
    "    \"RSC\": ['was led upstairs', 'onto the subway', 'to the hallway', 'drove to washington', 'back through london', 'and darted downstairs', 'past the offices', 'long hallway toward', 'down the sidewalk', 'back in manhattan', 'reached the interstate', 'just blocks away', 'drove from vermont', 'was standing outside', 'to a courtyard', 'in the alley', 'up the coast', 'from my dorm', 'in the courtyard', 'in central park', 'i walk outside', 'here in manhattan', 'darted downstairs', 'facing the beach', 'walk through downtown', 'wander the hallways', 'i ran downstairs', 'down the hall', \"'m standing outside\", 'off into vancouver', 'through the streets', 'sitting in indianapolis', 'on sixth avenue', 'i go upstairs', 'across the street', 'arrived in indianapolis', 'we were downtown'],\n",
    "    \"OPA\": ['railing looking out', 'across a plateau', 'up the coast', 'against the railing', 'in the courtyard', 'up the hill', 'above the gulf', 'outside the windows', 'long hallway toward', 'over the gulf', 'past the offices', 'through the windows', 'beside the river', 'past the waterfall', 'across the bridge', 'this long hallway', 'to a courtyard', 'and the courtyard', 'and behind me', 'down this embankment', 'towards the river', 'the hill up', 'courtyard was surrounded', 'in an alcove', 'onto the railing', 'along the coast', 'up the stairs', 'across the quadrangle', 'facing the beach', 'to the north', 'down the corridor', 'through the gates', 'over the embankment', 'onto the bridge', 'down that corridor', 'down the sidewalk', 'i looked across', 'path that jutted', 'through this door', 'the lagoon behind', 'down the embankment', 'on the railing', 'on the embankment', 'through the doors', 'on the windowsill', 'corridor out onto', 'the buildings beside', 'to the hallway', 'by that window', 'past the city', 'door behind me', 'to the south', 'off the coast', 'cross the bering', 'around the reef', 'behind me i', 'driveway and behind', 'against the windows', 'across the street', 'to the shoreline', 'lagoon behind the', 'on the sidewalk', 'hall past the', 'off the east', 'of the ravine', 'surrounded the city', 'in the window', 'southern shore of', 'in the distance', 'onto the sidewalk', 'i look across', 'behind us i', 'behind us there', 'on the cliff', 'over the river', 'toward the ocean', 'on that terrace', 'row of stalls', 'sidewalk in front', 'down the long', 'on the walls', 'door to the', 'by the window', 'outside my door', 'outside the door', 'across from me', 'on the eastern', 'the hall past', 'down the lagoon', 'in the forest', 'that window in', 'around me the', 'to the barrier', 'the gulf where', 'road in front', 'in the hallway', 'across the parking', 'in the colonnade', 'to the western', 'surrounded by rooms'],\n",
    "    \"PPA\": ['in an alcove', 'on the stoop', 'past the offices', 'against the railing', 'on the windowsill', 'in the alley', 'to a courtyard', 'the copier room', 'in the courtyard', 'this long hallway', 'to the hallway', 'on a dock', 'in the hallway', 'long hallway toward', 'outside the windows', 'on that terrace', 'inside the hut', 'railing looking out', 'through the windows', 'down this embankment', 'on the subway', 'onto the subway', 'there were shelves', 'in my cubicle', 'a strip mall', 'on the sidewalk', 'in the colonnade', 'on the railing', 'into the basement', 'across the parking', 'a restaurant stoop', 'onto the railing', 'exit the subway', 'by the window', 'in that attic', 'was led upstairs', 'in the basement', 'the food court', 'and the courtyard', 'in the cafeteria', 'hall past the', 'into the parking', 'in the windowless', 'back room where', 'on my bed', 'down the sidewalk', 'contain strip malls', 'onto the sidewalk', 'the hall closet', 'at those cliffs'],\n",
    "    \"RSC_only\": ['moved to chicago', 'drove from vermont', 'came to florida', 'here in manhattan', 'living in chicago',  'move to texas', 'leaving for france', 'back in manhattan', 'to boston to', 'went to boston', 'moved to vermont', 'geese in ohio', 'college in boston', 'in ohio', 'moved to brooklyn', 'normal suburban pittsburgh', 'moved to london', 'back in israel', 'to london to', 'come from israel', 'went to manchester', 'to columbus ohio', 'here in boston', 'i left vermont', 'from pittsburgh pennsylvania', 'in lower manhattan', 'hometown in texas', 'touring through europe', 'in warmer mexico', 'union in manhattan', 'suburban pittsburgh', 'moved to washington', 'was in boston', 'slacking in madison', 'chick from silverlake', 'heading to iraq', 'in chicago', 'in louisville kentucky', 'lived in hiroshima', 'in florida'],\n",
    "    \"OPA_only\": ['eventually i forgave', 'push past it', 'eventually forgave', 'she eventually forgave', 'i forgave', 'to see ourselves', 'of myself which', 'means extending empathy', 'forgive and', 'i stopped myself', 'forgive and love', 'of the hurt', 'i rise above', 'i pushed myself', 'is and who', \"'m hurt but\", 'see ourselves and', 'the hurt', 'i persisted and', 'to forgive afterwards', 'was real to', 'comparing myself', 'looked in myself', 'selves which', 'around it and', 'self which translated', 'inside me that', 'of me which', 'overcome my ambivalence', 'to push myself', 'was also influenced', 'the side which', 'side which', 'independence and freedom'],\n",
    "    \"PPA_only\": ['a garbage bag', 'that garbage bag', \"'re throwing napkins\", 'box of discarded', 'in sugar jars', 'their chew toys', 'those plastic containers', 'our dishwasher', 'skivvies toothbrush floss', 'of cheap beer', 'throwing napkins', 'a trash can', 'milk bottle tops', 'want a mcflurry', 'vomit smelling couch', 'grown napkins', 'my cheese sandwich', 'overpriced coffee shops', 'some lighter fluid', 'salad and stale', 'vomited a washpan', 'these brown paper'],\n",
    "    \"IPS\": ['and behind me', 'against the railing', 'onto the railing', 'path that jutted', 'situated herself behind', 'above the gulf', 'door behind me', 'southern shore of', 'i looked across', 'along the edge', 'closed behind me', 'behind me and', 'across a plateau', 'on the railing', 'up behind me', 'leaning against the', 'towering above me', 'jutted into the', 'onto the bridge', 'and cut across', 'behind him and', 'and came around', 'front of us', 'up onto the', 'over the gulf', 'stood behind me', 'across the bridge', 'beside the river'],\n",
    "    \"sPMv\": ['repeated her affirmation', 'said excuse me', 'asked i laughed', 'and goes hey', 'response was nah', 'hurry she exclaimed', 'said no i', 'just nodded yes', 'retorted rather loudly', 'was like hey', 'called her and', 'and said yes', 'and screams fuck', 'said uh hey', 'says sure and', 'says uh actually', 'was like hi', 'i said fine', 'said without hesitation', 'said well yes', 'says excuse me', 'i asked immediately', 'she yelled i', 'said mom mom', 'said did i', 'i said wow', 'i said shyly', 'asked her and', 'said okay okay', 'i sheepishly raise', 'which i responded', 'turned and said', 'then wrote yes', 'said yes i', 'whisper she said', 'was like mhm'],\n",
    "    \"EBA\": ['arms around her', 'wraps his arms', 'hands gripped the', 'into my palm', 'hands into my', 'elbows on knees', 'grab his arms', 'his hands folded', 'into her arms', 'grabbed her hand', 'arms flailing', 'grabbed her legs', 'arm around my', 'grabbed their hands', 'lifted her up', 'put my arms', 'leaned his head', 'put his arms', 'shakes my hand', 'flying arms flailing', 'i leaned down', 'arms tighten around', 'her hands gripped', 'hand on his', 'my feet kicking', 'pinning my arms', 'held her hand', 'in a headlock', 'pressed my face', 'holds her hand', 'arms flailing holding', 'rubbing his head'],\n",
    "    \"OFA\": ['and we talked', 'i even met', 'and so finally', 'one night my', 'one evening after', 'anyway the point', 'one summer my', 'weeks passed and', 'finally one day', 'then we talked', 'one night i', 'we chatted', 'and i talked', 'we talked and', 'talked and', 'so i texted', 'to my surprise', 'one afternoon when', 'i persisted and', 'and i finally', 'was watching television', 'i remember once', 'so one night', 'but anyway', 'and i met', 'when i finally', 'so i finally', 'on and on', 'son had finally', 'and i especially', 'so one day', 'and eventually i', 'we brace ourselves', 'so anyway', 'i was perusing', 'and it finally', 'later that day', 'so we finally', 'but anyhow', 'and as we', 'the day came', 'home one afternoon', 'then i finally', 'what fascinated me', 'and i vaguely', 'so i talked', 'once while i', 'was hanging out', 'i was reliving', 'but the most'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_clean = {\n",
    "    # numeric\n",
    "    'Numbers_only': 'Numbers',\n",
    "    'Time_only': 'Times',\n",
    "    'Years_only': 'Years',\n",
    "    'Measurements_only': 'Measurements',\n",
    "\n",
    "    # communication\n",
    "    'Relationships_only': 'Relationships',\n",
    "    'Dialogue_only':  'Dialogue',\n",
    "    'Introspection_only':  'Introspection',\n",
    "\n",
    "    # extra ROIs\n",
    "    'Gruesome': 'Gruesome body imagery',\n",
    "    'Clothing and Physical Appearance': 'Clothing and Physical Appearance',\n",
    "    'Colors': 'Colors',\n",
    "\n",
    "    # known ROIs\n",
    "    'OPA': 'Direction and location descriptions',\n",
    "    'PPA': 'Scenes and settings',\n",
    "    'RSC': 'Travel and location names',\n",
    "\n",
    "}\n",
    "ks = list(explanations_clean.keys())\n",
    "\n",
    "\n",
    "rows = {\n",
    "    # 'roi': rois,\n",
    "    'expl': [explanations_clean[k] for k in ks],\n",
    "    'top_ngrams_module_correct': [top_ngrams_clean[k] for k in ks],\n",
    "    # 'stability_score': [stability_scores[k.split('_')[0]] for k in ks],\n",
    "    'subject': [f'UT{subject}'] * len(ks),\n",
    "    # 'voxel_nums': [rois_dict[k.split('_')[0]] for k in ks],\n",
    "    'prompt_suffix': [explanation_avoid_suffixes[k] for k in ks],\n",
    "}\n",
    "rows = pd.DataFrame(rows)\n",
    "rows.to_pickle(f'rows_roi_ut{subject.lower()}_nov30_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_clean = {\n",
    "    'Sexual_and_Romantic_Interactions': 'Sexual and Romantic Interactions',\n",
    "    'Secretive_Or_Covert_Actions': 'Secretive Or Covert Actions',\n",
    "    'Recognition': 'Recognition',\n",
    "\n",
    "    'Positive Emotional Reactions': 'Positive Emotional Reactions',\n",
    "    'Negative Emotional Reactions': 'Negative Emotional Reactions',\n",
    "    'Professions': 'Professions and Personal Backgrounds',\n",
    "    'Fear and Avoidance': \"Fear and Avoidance\",\n",
    "\n",
    "    # known ROIs\n",
    "    'EBA': 'Body parts',\n",
    "    'IPS': 'Descriptive elements of scenes or objects',\n",
    "    'OFA': 'Conversational transitions',\n",
    "    # 'OPA': 'Direction and location descriptions',\n",
    "    'OPA_only': 'Self-reflection and growth',\n",
    "    # 'PPA': 'Scenes and settings',\n",
    "    'PPA_only': 'Garbage, food, and household items',\n",
    "    # 'RSC': 'Travel and location names',\n",
    "    'RSC_only': 'Location names',\n",
    "    'sPMv': 'Dialogue and responses',\n",
    "\n",
    "}\n",
    "ks = list(explanations_clean.keys())\n",
    "\n",
    "\n",
    "rows = {\n",
    "    # 'roi': rois,\n",
    "    'expl': [explanations_clean[k] for k in ks],\n",
    "    'top_ngrams_module_correct': [top_ngrams_clean[k] for k in ks],\n",
    "    # 'stability_score': [stability_scores[k.split('_')[0]] for k in ks],\n",
    "    'subject': [f'UT{subject}'] * len(ks),\n",
    "    # 'voxel_nums': [rois_dict[k.split('_')[0]] for k in ks],\n",
    "    'prompt_suffix': [explanation_avoid_suffixes[k] for k in ks],\n",
    "}\n",
    "rows = pd.DataFrame(rows)\n",
    "rows.to_pickle(f'rows_roi_ut{subject.lower()}_nov30_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S02 Export selected rois to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = ['RSC', 'OPA', 'PPA', 'IPS', 'pSTS', 'sPMv',\n",
    "        'EBA', 'OFA'] + ['RSC_only', 'OPA_only', 'PPA_only2']  # 'PPA_only1',\n",
    "# pprint({k: explanations[k] for k in rois})\n",
    "explanations_clean = {\n",
    "    'EBA': 'Body parts',\n",
    "    'IPS': 'Descriptive elements of scenes or objects',\n",
    "    'OFA': 'Personal growth and reflection',\n",
    "    'OPA': 'Direction and location descriptions',\n",
    "    'OPA_only': 'Spatial positioning and directions',\n",
    "    'PPA': 'Scenes and settings',\n",
    "    'PPA_only': 'Unappetizing foods',\n",
    "    'RSC': 'Travel and location names',\n",
    "    'RSC_only': 'Location names',\n",
    "    'pSTS': 'Verbal interactions',\n",
    "    'sPMv': 'Time and numbers'}\n",
    "explanation_avoid_suffixes = {\n",
    "    'EBA': ' Avoid mentioning any locations.',\n",
    "    'IPS': ' Avoid mentioning any locations.',\n",
    "    'OFA': ' Avoid mentioning any locations.',\n",
    "    'OPA': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'OPA_only': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'PPA': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'PPA_only': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'RSC': '',\n",
    "    'RSC_only': '',\n",
    "    'pSTS': ' Avoid mentioning any locations.',\n",
    "    'sPMv': ' Avoid mentioning any locations.'\n",
    "}\n",
    "for roi in rois:\n",
    "    print(f'\"{roi}\":', str(\n",
    "        top_ngrams_df[roi.replace('1', '').replace('2', '')].iloc[:50].values.tolist()) + ', ')\n",
    "    # {\n",
    "    # roi:  for roi in rois\n",
    "# })\n",
    "top_ngrams_clean = {\n",
    "    \"RSC\": ['drove from vermont', 'to washington', 'in manhattan', 'here in boston', 'off into vancouver', 'moved to chicago', 'was in mexico', 'arrived in indianapolis', 'came to florida', 'i left vermont'],\n",
    "    \"OPA\": ['onto the railing', 'towards the river', 'onto the sidewalk', 'towards the doors', 'outside the windows', 'long hallway toward', 'to the horizon', 'towards the street', 'over the gulf', 'to my left', 'path that jutted', 'on the ceiling', 'on the windowsill', 'down this embankment', 'up those stairs', 'above the gulf', 'facing the beach'],\n",
    "    \"PPA\": ['mile of cornfields', 'the windowsill', 'the rolling hills', 'beautiful moonlit mountains', 'giant stone cliffs', 'a strip mall', 'nondescript office buildings', 'manicured lawns', 'lakes', 'the dark driveway', 'and shimmering skyscrapers', 'a private beach', 'the leafy garden', 'our modest backyard', 'my dorm'],\n",
    "\n",
    "    \"RSC_only\": ['florida', 'israel', 'london', 'marrakesh', 'indianapolis', 'paris', 'pennsylvania', 'tokyo', 'tenessee', 'boston', 'vermont', 'chicago', 'indianapolis'],\n",
    "    \"OPA_only\": ['towards the ceiling', 'onto the railing', 'feet hanging over', 'towards the doors', 'seats behind', 'towards the door', 'lights peeking over', 'to my left', 'situated herself behind', 'you sit backward', 'to the horizon', 'maybe twelve feet', 'at the ceiling', 'towards the street', 'of seats behind', 'twenty feet above', 'his back turned', 'see the horizon', 'seats behind the', 'to my right', 'and high rafters', 'about twenty feet', 'door behind me', 'the door behind', 'toward the back', 'over his shoulder', 'feet above the', 'hands went underneath', 'towards the ground', 'his feet hanging', 'feet touch the', 'behind her and', 'stand in front', 'down one side', 'on opposite sides', 'over the ceiling', 'on either side'],\n",
    "    # \"PPA_only\": ['kind of corny', 'his painting sucked', 'snake oil', 'liar fake', 'fake name', 'bad puns', 'as an insult', 'called baloney'],\n",
    "    \"PPA_only2\": ['like burnt steak', 'like pudding', 'tasted pretty bad', 'stale baked goods', 'the crusts', 'baloney', 'yeast extract', 'a sandwich rejected',],\n",
    "\n",
    "    \"IPS\": ['there were slats', 'four connected squares', 'in long rows', 'on the sides', 'a long narrow', 'that forms horizontal', 'long rows of', 'sixty foot wide', 'between buttered slices', 'mile thick ice', 'all four corners', 'along the top'],\n",
    "    \"pSTS\": ['said excuse me', 'says excuse me', 'room went silent', 'someone shouted', 'i provoked gasps', 'somebody then yelled', 'she started laughing', 'excuse me', 'asked i laughed', 'exhalation someone shouted', 'retorted rather loudly', 'turned and said', 'hurry she exclaimed', 'i started yelling', 'say excuse me', 'i started laughing', 'interrupted the conversation', 'breath he yelled', 'moment she gasped', 'said guess what'],\n",
    "    \"sPMv\": ['one', 'forty', 'april nineteen forty', 'was sixteen seventeen', 'five only twenty', 'three down', 'march twentieth nineteen', 'more time passed', 'fifteen meters fifty', \"turning ninety\", 'june of nineteen'],\n",
    "    \"EBA\": ['wraps his arms', 'lifted her dress', 'arms flailing', 'hands gripped the', 'grabbed her legs', 'his hands folded', 'my feet kicking', 'navigated pushy elbows', 'elbows on knees', 'over his shoulder'],\n",
    "    \"OFA\": ['of my childhood', 'newfound self esteem', 'so my shrink', 'hurtful first dates', 'recall many instances', 'it felt magical', 'answered many questions', 'my school days', 'no satisfying fantasies', 'my mom often', 'from our childhood', 'growing up we', 'good friends often', 'shaped their mind', 'everything my parents'],\n",
    "}\n",
    "\n",
    "rows = {\n",
    "    'roi': rois,\n",
    "    'expl': [explanations_clean[k] for k in rois],\n",
    "    'top_ngrams_module_correct': [top_ngrams_clean[k] for k in rois],\n",
    "    'stability_score': [stability_scores[k.split('_')[0]] for k in rois],\n",
    "    'subject': [f'UT{subject}'] * len(rois),\n",
    "    'voxel_nums': [rois_dict[k.split('_')[0]] for k in rois],\n",
    "    'prompt_suffix': [explanation_avoid_suffixes[k] for k in rois],\n",
    "}\n",
    "rows = pd.DataFrame(rows)\n",
    "rows.to_pickle(f'rows_roi_ut{subject.lower()}_may31.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
