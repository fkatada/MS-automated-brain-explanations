{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from neuro import config\n",
    "import neuro.sasc.analyze_helper\n",
    "import neuro.sasc.viz\n",
    "import dvu\n",
    "import neuro.viz\n",
    "dvu.set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_name = 'pilot5_story_data.pkl'\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(config.RESULTS_DIR_LOCAL, 'processed', pilot_name))\n",
    "if pilot_name == 'pilot5_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20240604')\n",
    "\n",
    "# load responses\n",
    "default_story_idxs = np.where(\n",
    "    (np.array(stories_data_dict['story_setting']) == 'roi')\n",
    ")[0]\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in default_story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = defaultdict(list)\n",
    "use_clusters = False\n",
    "voxel_resps_dict = defaultdict(list)\n",
    "voxel_resps_dict_baseline = defaultdict(list)\n",
    "for story_num in default_story_idxs:\n",
    "    rows = stories_data_dict[\"rows\"][story_num]\n",
    "\n",
    "    # get resp_chunks\n",
    "    resp_story = resps_dict[\n",
    "        stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "            '_resps', '')\n",
    "    ].T  # (voxels, time)\n",
    "    timing = stories_data_dict[\"timing\"][story_num]\n",
    "    if 'paragraphs' in stories_data_dict.keys():\n",
    "        paragraphs = stories_data_dict[\"paragraphs\"][story_num]\n",
    "    else:\n",
    "        paragraphs = stories_data_dict[\"story_text\"][story_num].split(\n",
    "            \"\\n\\n\")\n",
    "    # paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "    if pilot_name in ['pilot3_story_data.pkl']:\n",
    "        paragraphs = [neuro.sasc.analyze_helper.remove_repeated_words(\n",
    "            p) for p in paragraphs]\n",
    "    assert len(paragraphs) == len(\n",
    "        rows), f\"{len(paragraphs)} != {len(rows)}\"\n",
    "    resp_chunks = neuro.sasc.analyze_helper.get_resps_for_paragraphs(\n",
    "        timing, paragraphs, resp_story, offset=2, validate=True)\n",
    "    assert len(resp_chunks) <= len(paragraphs)\n",
    "\n",
    "    # calculate mat\n",
    "    mat = np.zeros((len(rows), len(paragraphs)))\n",
    "    # mat_dict = {}\n",
    "    rois = rows['roi'].values\n",
    "    vox_nums = rows['voxel_nums']\n",
    "    for i in range(len(resp_chunks)):\n",
    "        mat[:, i] = [resp_chunks[i][x].mean()\n",
    "                     for x in rows['voxel_nums']]\n",
    "        voxel_resps_dict[rois[i]].append(\n",
    "            resp_chunks[i][vox_nums.iloc[i]].mean(axis=1))\n",
    "    for i in range(len(resp_chunks)):\n",
    "        # calculate baseline as mean of all other paragraphs excluding roi='RSC_only'\n",
    "        voxel_resps_dict_baseline[rois[i]].append(\n",
    "            np.mean([resp_chunks[j][vox_nums.iloc[i]].mean(axis=1)\n",
    "                     for j in range(len(resp_chunks))\n",
    "                     if (not rois[j] in ['RSC_only', 'PPA_only2', 'OPA_only'] and not j == i)], axis=0))\n",
    "\n",
    "    mat[:, 0] = np.nan  # ignore the first column\n",
    "    # print('mat', mat)\n",
    "\n",
    "    args = np.argsort(rows[\"roi\"].values)\n",
    "    mat = mat[args, :][:, args]\n",
    "    mats[use_clusters].append(deepcopy(mat))\n",
    "\n",
    "    # plt.imshow(mat)\n",
    "    # plt.colorbar(label=\"Mean response\")\n",
    "    # plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "    # plt.ylabel(\"Voxel\")\n",
    "    # plt.show()\n",
    "\n",
    "if 'voxel_num' in rows.columns:\n",
    "    rows = rows.sort_values(by=\"voxel_num\")\n",
    "else:\n",
    "    rows = rows.sort_values(by=\"roi\")\n",
    "expls = rows[\"expl\"].values\n",
    "\n",
    "\n",
    "m = {}\n",
    "mats[use_clusters] = np.array(mats[use_clusters])  # (6, 17, 17)\n",
    "m[use_clusters] = np.nanmean(mats[use_clusters], axis=0)\n",
    "mats_std = np.nanstd(mats[use_clusters], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI heatmap full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pilot_name == 'pilot5_story_data.pkl'\n",
    "# note: some voxels didn't have good clusters so they will be missing from these plots...\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "\n",
    "neuro.sasc.viz.outline_diagonal(m1.shape, color='black', lw=1, block_size=1)\n",
    "\n",
    "s = 'small'\n",
    "# expls_order = analyze_helper.sort_expls_semantically(expls, device='cuda')\n",
    "rois = rows[\"roi\"].values\n",
    "expls_order = np.argsort(rois)\n",
    "m_plot = m1[expls_order][:, expls_order]  # [:, expls_order]\n",
    "\n",
    "rois = rois[expls_order]\n",
    "neuro.sasc.viz.imshow_diverging(\n",
    "    m_plot, clab=\"Mean response ($\\sigma$)\", clab_size='large')\n",
    "plt.xlabel(\"Driving paragraph\",  # \\n(Ideally, diagonal should be brighter)\",\n",
    "           fontsize='large')\n",
    "\n",
    "# plt.ylabel(\"Voxel\", fontsize='x-small')\n",
    "# labs = expls[expls_order]\n",
    "\n",
    "plt.ylabel(\"ROI response\", fontsize='large')\n",
    "# labs = [f'{i + 1:02d}' for i in range(len(expls_order))]\n",
    "labs = expls[expls_order]\n",
    "for i in range(len(labs)):\n",
    "    print(labs[i], expls[expls_order[i]])\n",
    "\n",
    "plt.yticks(labels=[x.replace('_only', '') for x in rois], ticks=np.arange(\n",
    "    len(expls)), fontsize=s)\n",
    "plt.xticks(labels=[x.replace('2', '').replace('_', '-') for x in rois], ticks=np.arange(\n",
    "    len(expls)), rotation=90, fontsize=s)\n",
    "plt.tight_layout()\n",
    "neuro.viz.savefig(join('roi',\n",
    "                       pilot_name[:pilot_name.index('_')] + '_roi_heatmap.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned up means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(voxel_resps_dict['sPMv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_voxel_means = {\n",
    "    k: np.vstack(voxel_resps_dict[k]).mean(axis=0)\n",
    "    for k in rows['roi']\n",
    "}\n",
    "roi_voxel_baselines = {\n",
    "    k: np.vstack(voxel_resps_dict_baseline[k]).mean(axis=0)\n",
    "    for k in rows['roi']\n",
    "}\n",
    "roi_voxel_diffs = {\n",
    "    k: v - roi_voxel_baselines[k]\n",
    "    for k, v in roi_voxel_means.items()\n",
    "}\n",
    "\n",
    "\n",
    "roi_voxel_tups = [\n",
    "    (k, v)\n",
    "    # for k, l in roi_voxel_means.items()\n",
    "    for k, l in roi_voxel_diffs.items()\n",
    "    for v in l]\n",
    "\n",
    "# convert tups to dataframe\n",
    "roi_voxel_df = pd.DataFrame(roi_voxel_tups, columns=['roi', 'voxel_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# filter out RSC_only, and PPA_only\n",
    "roi_voxel_df = roi_voxel_df[~roi_voxel_df['roi'].isin(\n",
    "    ['RSC_only', 'PPA_only2', 'OPA_only'])]\n",
    "\n",
    "# rotate xlabels to avoid overlap\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# sns.stripplot(x='roi', y='voxel_mean', data=roi_voxel_df, color='black', alpha=0.1)\n",
    "# sns.violinplot(x='roi', y='voxel_mean', data=roi_voxel_df) #, alpha=0.1)\n",
    "plt.ylabel('Mean driving\\nvoxel response ($\\sigma$)', fontsize='large')\n",
    "sns.barplot(x='roi', y='voxel_mean', data=roi_voxel_df,\n",
    "            errorbar='se', alpha=0.5, color='C0',\n",
    "            order=['EBA', 'IPS', 'OFA', 'pSTS', 'sPMv', 'RSC', 'PPA', 'OPA'])\n",
    "\n",
    "# rotate xlabels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('ROI', fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/main',\n",
    "            pilot_name[:pilot_name.index('_')] + '_roi_voxel_barplot.pdf'), bbox_inches='tight')\n",
    "# plt.axhline(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = {}\n",
    "for roi in roi_voxel_means.keys():\n",
    "    vals = roi_voxel_df[roi_voxel_df['roi'] == roi]['voxel_mean'].values\n",
    "    # vals = vals[~np.isnan(vals)]\n",
    "\n",
    "    # do t-test\n",
    "    p_vals[roi] = scipy.stats.ttest_1samp(vals, 0).pvalue\n",
    "\n",
    "\n",
    "p_vals = {k: v for k, v in p_vals.items() if not np.isnan(v)}\n",
    "p_vals_corrected = scipy.stats.false_discovery_control(list(p_vals.values()))\n",
    "p_vals_corrected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make average plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate means\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "diag_means = np.diag(m1)\n",
    "off_diag_means = np.nanmean(m1, axis=1) - (diag_means / len(diag_means))\n",
    "neuro.sasc.viz.barplot_default([diag_means], [off_diag_means],\n",
    "                         pilot_name, expls, annot_points=False)\n",
    "joblib.dump({'diag_means': diag_means,\n",
    "            'off_diag_means': off_diag_means}, join(config.RESULTS_DIR, 'processed', pilot_name.replace('_story_data.pkl', '_default_means.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in rows[['roi', 'expl']].values:\n",
    "    print(tup[0] + ': ', tup[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_df(mats1, melt=False):\n",
    "    d = defaultdict(list)\n",
    "    story_names = resp_np_files\n",
    "    for i in range(len(mats1)):\n",
    "        m = mats1[i]\n",
    "        d['driving'].append(np.nanmean(np.diag(m)))\n",
    "        d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "        d['story'].append(story_names[i].replace('.npy', ''))\n",
    "    d = pd.DataFrame.from_dict(d)\n",
    "    # d['diff'] = d['driving'] - d['baseline']\n",
    "    if melt:\n",
    "        d = d.melt(id_vars='story', value_vars=[\n",
    "            'driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "        d = d[d.condition == 'driving']\n",
    "    return d\n",
    "\n",
    "\n",
    "use_clusters = False\n",
    "mats1 = mats[use_clusters]\n",
    "story_scores_df = get_story_df(mats1)\n",
    "joblib.dump(story_scores_df, join(config.RESULTS_DIR, 'processed',\n",
    "            pilot_name.replace('_story_data.pkl', '_roi_story_scores.pkl')))\n",
    "\n",
    "sasc.viz.stories_barplot(story_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI heatmap truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pilot_name == 'pilot5_story_data.pkl'\n",
    "# note: some voxels didn't have good clusters so they will be missing from these plots...\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "\n",
    "plt.figure(figsize=(7, 3.9))\n",
    "\n",
    "dvu.outline_diagonal(m1.shape, color='black', lw=1, block_size=1, roffset=0)\n",
    "dvu.outline_diagonal(m1.shape, color='black', lw=1, block_size=1, roffset=3)\n",
    "\n",
    "s = 'medium'\n",
    "rois = rows.sort_values(by='roi')\n",
    "rois['idx'] = np.arange(len(rois))\n",
    "rois.set_index('roi', inplace=True)\n",
    "rois_y = ['RSC', 'PPA', 'OPA']\n",
    "rois_x = ['RSC', 'PPA', 'OPA',  'RSC_only', 'PPA_only2', 'OPA_only']\n",
    "expls_order_y = rois.loc[rois_y]['idx'].values\n",
    "expls_order_x = rois.loc[rois_x]['idx'].values\n",
    "m_plot = m1[expls_order_y][:, expls_order_x]  # [:, expls_order]\n",
    "\n",
    "\n",
    "neuro.sasc.viz.imshow_diverging(\n",
    "    # , vabs_multiplier=0.7)\n",
    "    m_plot, clab=\"Mean response ($\\sigma$)\", clab_size='large')\n",
    "plt.xlabel(\"Driving paragraph\",  # \\n(Ideally, diagonal should be brighter)\",\n",
    "           fontsize='large')\n",
    "\n",
    "plt.ylabel(\"ROI response\", fontsize='large')\n",
    "labs = expls[expls_order]\n",
    "for i in range(len(labs)):\n",
    "    print(labs[i], expls[expls_order[i]])\n",
    "\n",
    "\n",
    "plt.yticks(labels=[x.replace('_only', '').replace('2', '') for x in rois_y], ticks=np.arange(\n",
    "    len(rois_y)), fontsize=s)\n",
    "plt.xticks(labels=[x.replace('2', '').replace('_', '-') for x in rois_x], ticks=np.arange(\n",
    "    len(rois_x)), rotation=45, fontsize=s)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join('roi', pilot_name[:pilot_name.index('_')] + '_roi_heatmap.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation test on diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "mm = pd.DataFrame(m1, index=rows['roi'], columns=rows['roi']).T\n",
    "mm['PPA_diff'] = mm['PPA_only2'] - (mm['RSC_only'] + mm['OPA_only'])/2\n",
    "mm['RSC_diff'] = mm['RSC_only'] - (mm['PPA_only2'] + mm['OPA_only'])/2\n",
    "mm['OPA_diff'] = mm['OPA_only'] - (mm['RSC_only'] + mm['PPA_only2'])/2\n",
    "mm = mm[['RSC_diff', 'PPA_diff', 'OPA_diff']]\n",
    "# rotate the index labels\n",
    "sns.heatmap(mm, cmap='coolwarm',\n",
    "            cbar_kws={'label': 'Mean response ($\\sigma$)'}, square=True,)\n",
    "plt.ylabel(\"Driving paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_vals = defaultdict(list)\n",
    "drive_vals = defaultdict(list)\n",
    "for i in range(len(mats[False])):\n",
    "\n",
    "    mm = pd.DataFrame(mats[False][i], index=rows['roi'], columns=rows['roi']).T\n",
    "    mm['PPA_diff'] = mm['PPA'] - (mm['RSC'] + mm['OPA'])/2\n",
    "    mm['RSC_diff'] = mm['RSC'] - (mm['PPA'] + mm['OPA'])/2\n",
    "    mm['OPA_diff'] = mm['OPA'] - (mm['RSC'] + mm['PPA'])/2\n",
    "    mm = mm[['RSC_diff', 'PPA_diff', 'OPA_diff']]\n",
    "    # mm = mm[['RSC_diff', 'PPA_diff', 'OPA_diff']]\n",
    "    # print(mm)\n",
    "    drive_vals['RSC_diff'].append(mm['RSC_diff'].loc['RSC_only'])\n",
    "    drive_vals['PPA_diff'].append(mm['PPA_diff'].loc['PPA_only2'])\n",
    "    drive_vals['OPA_diff'].append(mm['OPA_diff'].loc['OPA_only'])\n",
    "    \n",
    "    # append all but the drive vals to baseline\n",
    "    baseline_vals['RSC_diff'].extend(mm['RSC_diff'].loc[mm.index != 'RSC_only'])\n",
    "    baseline_vals['PPA_diff'].extend(mm['PPA_diff'].loc[mm.index != 'PPA_only2'])\n",
    "    baseline_vals['OPA_diff'].extend(mm['OPA_diff'].loc[mm.index != 'OPA_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation test taking nanmean of 4 vals\n",
    "def permutation_test(vals1, vals_baseline, n_permutations=10000):\n",
    "    obs = np.nanmean(vals1)\n",
    "    n_obs = len(vals1)\n",
    "    count = 0\n",
    "    for _ in tqdm(range(n_permutations)):\n",
    "        np.random.shuffle(vals_baseline)\n",
    "        if obs >= np.nanmean(vals_baseline[:n_obs]):\n",
    "            count += 1\n",
    "    return 1 - count / n_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 35676.98it/s]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]/tmp/ipykernel_315110/207662289.py:8: RuntimeWarning: Mean of empty slice\n",
      "  if obs >= np.nanmean(vals_baseline[:n_obs]):\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 33208.64it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 35256.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.00019999999999997797, 0.48160000000000003)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_test(drive_vals['RSC_diff'], baseline_vals['RSC_diff']), \\\n",
    "    permutation_test(drive_vals['PPA_diff'], baseline_vals['PPA_diff']), \\\n",
    "    permutation_test(drive_vals['OPA_diff'], baseline_vals['OPA_diff'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
