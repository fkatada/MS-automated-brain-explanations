{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import random\n",
    "import feature_spaces\n",
    "import encoding_utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import feature_spaces\n",
    "import config\n",
    "fit_encoding = __import__('01_fit_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    feature_space = 'qa_embedder-10'\n",
    "    qa_embedding_model = 'mistralai/Mistral-7B-v0.1'\n",
    "    trim = 5\n",
    "    num_stories = -1\n",
    "\n",
    "\n",
    "args = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "story_names = story_names_train + story_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in story_names:\n",
    "    for qa_embedding_model in ['mistralai/Mistral-7B-v0.1', 'mistralai/Mixtral-8x7B-v0.1']:\n",
    "        cache_hash = feature_spaces._get_cache_hash(\n",
    "            story=story,\n",
    "            checkpoint='qa_embedder',\n",
    "            num_ngrams_context=25,\n",
    "            qa_embedding_model=qa_embedding_model,\n",
    "            qa_questions_version='v1-end',\n",
    "            num_trs_context=None,\n",
    "            num_secs_context_per_word=None,\n",
    "        )\n",
    "        cache_file = join(\n",
    "            config.cache_embs_dir, f'{cache_hash}.jl')\n",
    "        if os.path.exists(cache_file):\n",
    "            os.remove(cache_file)\n",
    "            print(f'Removed {cache_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
