{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "from typing import List\n",
    "from mprompt.modules.emb_diff_module import EmbDiffModule\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imodelsx.util\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import sasc.notebook_helper\n",
    "import scipy.special\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from mprompt.methods.m4_evaluate import D5_Validator\n",
    "import openai\n",
    "from mprompt.modules.fmri_module import fMRIModule\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "from mprompt.config import RESULTS_DIR\n",
    "import torch.cuda\n",
    "\n",
    "r = (pd.read_pickle('../results/results_fmri_full.pkl')\n",
    "    .sort_values(by=['top_score_synthetic'], ascending=False))\n",
    "\n",
    "EXPT_NAME = 'relationships_mar9'\n",
    "rows = joblib.load(join(RESULTS_DIR, 'stories', f'{EXPT_NAME}_rows.pkl'))\n",
    "expls = rows.expl.values\n",
    "voxel_nums = rows.module_num.values\n",
    "subjects = rows.subject.values\n",
    "paragraphs = rows.paragraph.values\n",
    "prompts = rows.prompt.values\n",
    "\n",
    "scores_all_data = joblib.load(join(RESULTS_DIR, 'stories', f'{EXPT_NAME}_scores_data.pkl'))['scores_all']\n",
    "# keys: scores_mod, scores_max_mod, all_scores, all_ngrams\n",
    "scores_all_mod = joblib.load(join(RESULTS_DIR, 'stories', f'{EXPT_NAME}_scores_mod.pkl'))['scores_all']\n",
    "# scores_mod = scores_mod_dict['scores_mod']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "Explanation & Subject & ROI & \\makecell[r]{fMRI correlation\\\\(test)} & \\makecell[r]{Synthetic\\\\data score} & \\makecell[r]{Fraction of matching\\\\ngrams (module, top-75)} \\\\\n",
      "\\midrule\n",
      "looking or staring in some way & UTS03 & IFSFP & 0.53 & 0.10 & 0.40 \\\\\n",
      "relationships and milestones in life & UTS02 & PMvh, AC & 0.35 & 0.07 & 0.55 \\\\\n",
      "passing of time & UTS02 & PMvh, AC & 0.41 & 0.07 & 0.28 \\\\\n",
      "food and drink & UTS01 & Broca & 0.41 & 0.06 & 0.52 \\\\\n",
      "hands and arms & UTS01 & EBA, PMvh, S2F & 0.30 & 0.05 & 0.87 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows\n",
    "columns = {\n",
    "    # explanation\n",
    "    'top_explanation_init_strs': 'Explanation',\n",
    "\n",
    "    # fmri stuff\n",
    "    'subject': 'Subject',\n",
    "    # 'module_num': 'Voxel',\n",
    "    'roi_func': 'ROI',\n",
    "    # 'roi_anat': 'ROI (anatomical)',\n",
    "    'fmri_test_corr': '\\\\makecell[r]{fMRI correlation\\\\\\\\(test)}',\n",
    "    \n",
    "    # scores\n",
    "    'top_score_synthetic': '\\\\makecell[r]{Synthetic\\\\\\\\data score}',\n",
    "    'frac_top_ngrams_module_correct': '\\\\makecell[r]{Fraction of matching\\\\\\\\ngrams (module, top-75)}',\n",
    "    # 'rankcorr_expl_test': 'Correlation (test) when predicting with only explanation',\n",
    "    # 'frac_top_ngrams_test_correct': 'Fraction of matching ngrams (test, top-75)',\n",
    "        \n",
    "    # ngrams matching the explanation (used 75 ngrams)\n",
    "    # 'top_ngrams_module_correct': 'Matching top ngrams (out of top-75)',\n",
    "    # 'top_ngrams_test_correct': 'Matching ngrams (test, top-75)',\n",
    "\n",
    "    # all ngrams\n",
    "    # 'top_ngrams_module_25': 'All top ngrams (top-25)',\n",
    "    # 'top_ngrams_test_25': 'Top ngrams (test, top-25)',\n",
    "\n",
    "    # alternative explanations\n",
    "    # 'explanation_init_strs': 'Explanation candidates',\n",
    "}\n",
    "\n",
    "tab = (\n",
    "    rows\n",
    "    .sort_values(by=['top_score_synthetic'], ascending=False)\n",
    "    # .sort_values(by=['rankcorr_expl_test'], ascending=False)\n",
    "    .filter(columns.keys())\n",
    "    .rename(columns=columns)\n",
    "    .round(3)\n",
    ")\n",
    "with pd.option_context('display.max_colwidth', -1, 'display.max_rows', 200):\n",
    "    tab_join_lists = tab.applymap(lambda x: ', '.join(x) if isinstance(x, np.ndarray) or isinstance(x, list) else x)\n",
    "    # display(\n",
    "        # tab_join_lists.head(3)\n",
    "    # )\n",
    "    print(tab_join_lists.style.hide(axis='index').format(precision=2).to_latex(hrules=True))\n",
    "    # tab_join_lists.to_csv('../results/results_fmri.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meandiags 0.2547008547008547 meanoff 0.041025641025641026\n",
      "meandiags 0.044020334554224334 meanoff 0.018610744476272468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2099606/2840335649.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  diff, sem = get_diff_and_sem_diag_vs_off_diag(np.array(scores_all_data))\n",
      "/tmp/ipykernel_2099606/2840335649.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  diff, sem = get_diff_and_sem_diag_vs_off_diag(np.array(scores_all_mod))\n"
     ]
    }
   ],
   "source": [
    "def get_diff_and_sem_diag_vs_off_diag(arr: np.ndarray[List]):\n",
    "    # difference between diagonal and off-diagonal\n",
    "    eye = np.eye(arr.shape[0]).astype(bool)\n",
    "    diag = arr[eye]\n",
    "    off_diag = arr[~eye]\n",
    "\n",
    "    # individual elements\n",
    "    diags = np.hstack(diag).astype(float).tolist()\n",
    "    off_diags = np.hstack(off_diag).astype(float).tolist()\n",
    "    diff = np.mean(diags) - np.mean(off_diags)\n",
    "    # print('meandiags', np.mean(diags), 'meanoff', np.mean(off_diags))\n",
    "    sem = np.sqrt(np.var(diags) / len(diags) + np.var(off_diags) / len(off_diags))\n",
    "    return diff, sem\n",
    "\n",
    "mets = {}\n",
    "diff, sem = get_diff_and_sem_diag_vs_off_diag(np.array(scores_all_data))\n",
    "mets['Explanation difference'] = [f'{diff:.3f} \\err' + '{' + f'{sem:.3f}' + '}']\n",
    "diff, sem = get_diff_and_sem_diag_vs_off_diag(np.array(scores_all_mod))\n",
    "mets['Module response difference'] = [f'{diff:.3f} \\err' + '{' + f'{sem:.3f}' + '}']\n",
    "n = r.shape[0]\n",
    "mets['Test rank correlation'] = [f'{r[\"rankcorr_expl_test\"].mean():.3f} \\err' + '{' + f'{r[\"rankcorr_expl_test\"].std()/np.sqrt(n):.3f}' + '}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "Explanation difference & Module response difference & Test rank correlation \\\\\n",
      "\\midrule\n",
      "0.214 \\err{0.018} & 0.025 \\err{0.005} & 0.031 \\err{0.005} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(mets).style.hide(axis='index').format(precision=2).to_latex(hrules=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
