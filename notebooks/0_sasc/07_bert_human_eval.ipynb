{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "import pandas as pd\n",
    "import joblib\n",
    "# from mprompt.config import RESULTS_DIR\n",
    "import torch.cuda\n",
    "import json\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn.decomposition\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "import adjustText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import joblib\n",
    "import os\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from mprompt.config import RESULTS_DIR\n",
    "\n",
    "HUMAN_EVAL_DIR = join(RESULTS_DIR, 'bert', 'human_eval')\n",
    "# f'b_l{factor_layer}_i{factor_idx}')\n",
    "fnames = os.listdir(HUMAN_EVAL_DIR)\n",
    "evals = []\n",
    "for fname in fnames:\n",
    "    fdir = os.listdir(join(HUMAN_EVAL_DIR, fname))[0]\n",
    "    evals.append(joblib.load(join(HUMAN_EVAL_DIR, fname, fdir, 'eval.pkl')))\n",
    "df = pd.DataFrame([pd.Series(x) for x in evals])\n",
    "scores_recovered = joblib.load(join(RESULTS_DIR, 'bert', 'wiki_norm_std', 'wiki_our_syn_perc_std_score.pkl'))\n",
    "df = df[['factor_layer', 'factor_idx', 'explanation_init_strs', 'score_synthetic_std']]\n",
    "df['score_synthetic_std'] = df['score_synthetic_std'].apply(lambda x: x[0][0]).astype(float)\n",
    "df['score_recovered'] = df.apply(lambda x: scores_recovered[x['factor_layer']][x['factor_idx']], axis=1)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'explanation_init_strs': 'explanation_human',\n",
    "        'score_synthetic_std': 'score_human',\n",
    "    }\n",
    ")\n",
    "df['explanation_human'] = df['explanation_human'].apply(lambda x: x[0])\n",
    "\n",
    "# add bert expl\n",
    "expls_scores_bert = joblib.load(join(RESULTS_DIR, 'bert', 'wiki_norm_std', 'wiki_our_syn_perc_std_score.pkl'))\n",
    "expls_bert = joblib.load(join(RESULTS_DIR, 'bert', 'expls_bert.jbl'))\n",
    "df_bert = pd.DataFrame.from_dict({\n",
    "    'factor_layer': sum([[i] * 1500 for i in range(13)], []),\n",
    "    'score': expls_scores_bert.flatten(),\n",
    "    'expl': expls_bert,\n",
    "    'factor_idx': sum([list(range(1500)) for i in range(13)], []),\n",
    "})\n",
    "df['explanation_method'] = df.apply(\n",
    "    lambda x: df_bert[(df_bert['factor_layer'] == x['factor_layer']) & \\\n",
    "                      (df_bert['factor_idx'] == x['factor_idx'])]['expl'].values[0],\n",
    "    axis=1)\n",
    "\n",
    "df.to_pickle(join(RESULTS_DIR, 'results_bert_human_eval.pkl'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['score_human', 'score_recovered']].mean())\n",
    "# print(df_human[['score_human', 'score_recovered']].sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('win percentage', (df['score_recovered'] > df['score_human']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = {\n",
    "        'factor_layer': 'Factor Layer',\n",
    "        'factor_idx': 'Factor Index',\n",
    "        'explanation_human': 'Explanation (Human)',\n",
    "        'explanation_method': 'Explanation (Ours)',\n",
    "        'score_human': 'Explanation score (Human)',\n",
    "        'score_recovered': 'Explanation score (Ours)',\n",
    "    }\n",
    "print(df.rename(columns=ks)[list(ks.values())].style.hide(axis='index').format(precision=2).to_latex(hrules=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
