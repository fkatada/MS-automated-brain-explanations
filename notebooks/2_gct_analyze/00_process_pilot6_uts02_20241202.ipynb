{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num, add_stability_score\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR\n",
    "import re\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "def extract_number(string):\n",
    "    return int(re.findall(r'\\d+', string)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the info from stories into a single pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stuff\n",
    "# double check all of these, intro paragraph may be the same...\n",
    "output_file = join(sasc.config.RESULTS_DIR,\n",
    "                   'processed', \"pilot6_story_data.pkl\")\n",
    "STORY_DATA_DIR = join(FMRI_DIR, 'brain_tune', 'story_data', '20241202')\n",
    "story_mapping = {\n",
    "    'roi/uts02___roi_nov30___seed=1': 'GenStory30.npy',\n",
    "    'roi/uts02___roi_nov30___seed=2': 'GenStory31.npy',\n",
    "    'roi/uts02___roi_nov30___seed=3': 'GenStory32.npy',\n",
    "    'roi/uts02___roi_nov30___seed=7': 'GenStory33.npy',\n",
    "    'roi/uts02___roi_nov30___seed=8': 'GenStory34.npy',\n",
    "    'roi/uts02___roi_nov30___seed=9': 'GenStory35.npy',\n",
    "}\n",
    "\n",
    "# cluster_neighbors = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"cluster_neighbors_v1.pkl\"))\n",
    "perfs = joblib.load(join(sasc.config.FMRI_DIR, 'sasc', 'rj_models',\n",
    "                    'opt_model', 'new_setup_performance.jbl'))\n",
    "\n",
    "# add keys\n",
    "stories_data_dict = defaultdict(list)\n",
    "for story_idx, story_name in enumerate(story_mapping.keys()):\n",
    "    # add scalar story descriptions\n",
    "    stories_data_dict[\"story_name_original\"].append(story_name)\n",
    "    stories_data_dict[\"story_setting\"].append(story_name.split(\"/\")[0])\n",
    "    stories_data_dict[\"story_name_new\"].append(story_mapping[story_name])\n",
    "    story_fname = [f for f in os.listdir(join(STORIES_DIR, story_name))\n",
    "                   if f.startswith('uts02_story')][0]\n",
    "    story_text = open(join(STORIES_DIR, story_name, story_fname), \"r\").read()\n",
    "    stories_data_dict[\"story_text\"].append(story_text)\n",
    "    prompts_paragraphs = joblib.load(\n",
    "        join(STORIES_DIR, story_name, \"prompts_paragraphs.pkl\")\n",
    "    )\n",
    "    prompts_paragraphs['paragraphs'] = story_text.split(\"\\n\\n\")\n",
    "    assert len(prompts_paragraphs['paragraphs']) == len(\n",
    "        prompts_paragraphs['prompts'])\n",
    "\n",
    "    # add paragraph-level descriptions\n",
    "    timings = pd.read_csv(\n",
    "        # join(STORIES_DIR, story_name, \"timings_processed.csv\")\n",
    "        join(STORY_DATA_DIR,\n",
    "             f'timings_processed{extract_number(story_mapping[story_name])}.csv'),\n",
    "        header=None,\n",
    "    ).rename(columns={0: 'word', 2: 'time_running'})\n",
    "    timings['time_running'] *= 0.75\n",
    "    # = timings['time_running'].apply(\n",
    "    # lambda x: x * 0.75)\n",
    "    # add offset to timings\n",
    "    # timings['time_running']  # += 10  # -= 5  # += 6\n",
    "    stories_data_dict[\"timing\"].append(timings)\n",
    "    stories_data_dict[\"prompts\"].append(prompts_paragraphs[\"prompts\"])\n",
    "    stories_data_dict[\"paragraphs\"].append(prompts_paragraphs[\"paragraphs\"])\n",
    "\n",
    "    # add paragraph-level metadata\n",
    "    story_metadata_per_paragraph = pd.read_pickle(\n",
    "        join(STORIES_DIR, story_name, \"rows.pkl\"))\n",
    "    stories_data_dict[\"rows\"].append(story_metadata_per_paragraph)\n",
    "\n",
    "joblib.dump(stories_data_dict, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_data_dir = join(sasc.config.PILOT_STORY_DATA_DIR, '20241202')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load responses\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace(\n",
    "    '_resps', '') for i in range(len(stories_data_dict['story_name_new']))]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stories_data_dict[\"story_name_new\"])):\n",
    "    story_name = stories_data_dict[\"story_name_new\"][i]\n",
    "    timings = stories_data_dict[\"timing\"][i]\n",
    "    # trs = ceil(timings['time_running'].max() * 0.75 / 2) - 10\n",
    "    trs = ceil(timings['time_running'].max() / 2) - 10\n",
    "    print(story_name, trs, resps_dict[story_name].shape[0])\n",
    "\n",
    "    assert trs == resps_dict[story_name].shape[0]\n",
    "    # print('resp trs', resps_dict[story_name].shape[0])\n",
    "    # print(story_name.replace('_resps', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
