{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imodelsx.util\n",
    "from copy import deepcopy\n",
    "import re\n",
    "# import notebook_helper\n",
    "import sasc.viz\n",
    "import scipy.special\n",
    "import pandas as pd\n",
    "from sasc.config import RESULTS_DIR\n",
    "timings_module = __import__('03_timings')\n",
    "setting = \"qa\"\n",
    "EXPT_NAMES = [\n",
    "    k\n",
    "    for k in os.listdir(join(RESULTS_DIR, \"stories\", setting))\n",
    "    # if \"uts03\" in k or \"uts01\" in k\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neuro.features.stim_utils\n",
    "# import neuro.data.story_names\n",
    "# wordseqs = neuro.features.stim_utils.load_story_wordseqs_huge(\n",
    "#     stories=neuro.data.story_names.get_story_names(all=True))\n",
    "# diffs = [\n",
    "#     np.diff(w.data_times)\n",
    "#     for w in wordseqs.values()\n",
    "# ]\n",
    "# diffs = np.concatenate(diffs)\n",
    "# # diffs = diffs[diffs < 2]\n",
    "# plt.hist(diffs, cumulative=True, density=True)\n",
    "# print('mean', np.mean(diffs), 'min', np.min(diffs), 'max', np.max(diffs))\n",
    "# # mean 0.3740945421461178"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skipped = 0\n",
    "n_processed = 0\n",
    "for EXPT_NAME in EXPT_NAMES:\n",
    "    EXPT_DIR = join(RESULTS_DIR, 'stories', setting, EXPT_NAME)\n",
    "    timings_file = join(EXPT_DIR, 'timings.csv')\n",
    "    if not os.path.exists(timings_file):\n",
    "        print('skipping', EXPT_NAME)\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "    # if os.path.exists(join(EXPT_DIR, 'timings_processed.csv')):\n",
    "        # print('already processed', EXPT_NAME)\n",
    "        # n_processed += 1\n",
    "\n",
    "    print('processing', EXPT_NAME)\n",
    "\n",
    "    df = pd.read_csv(timings_file)\n",
    "    print('shape', df.shape)\n",
    "    try:\n",
    "        df = timings_module.process_timings(df)\n",
    "        df.to_csv(join(EXPT_DIR, 'timings_processed.csv'), index=False)\n",
    "        n_processed += 1\n",
    "        print('\\tmean', df['timing'].mean(), 'min',\n",
    "              df['timing'].min(), 'max', df['timing'].max())\n",
    "        print('\\ttotal time', df['time_running'].max()/60, 'min')\n",
    "    except Exception as e:\n",
    "        print('error', e)\n",
    "        print('skipping', EXPT_NAME)\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "print('n_skipped', n_skipped, 'n_processed', n_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(RESULTS_DIR, 'stories', 'default',\n",
    "                 'uts03___jun14___seed=3', 'timings_processed.csv'))\n",
    "\n",
    "# Plotting legend\n",
    "df['ends_in'] = 'Normal'\n",
    "df.loc[df['ends_in_period'], 'ends_in'] = 'Period'\n",
    "df.loc[df['ends_in_comma'], 'ends_in'] = 'Comma'\n",
    "# df = df.sort_values(by='ends_in')\n",
    "\n",
    "# Make plot\n",
    "sns.lmplot(data=df, x='word_len', y='timing', hue='ends_in',\n",
    "           markers='.', legend=False, aspect=1.5)\n",
    "plt.xlabel('Word length (characters)')\n",
    "plt.ylabel('Word timing (sec)')\n",
    "plt.axhline(np.mean(df['timing']), color='gray')\n",
    "plt.text(16, np.mean(df['timing']) - 0.02,\n",
    "         f'Mean: {np.mean(df[\"timing\"]):.2f} sec', color='gray')\n",
    "# change legend label value\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.gca().legend(bbox_to_anchor=(1, 0.7), labelcolor='linecolor')\n",
    "# plt.gca().legend(handles=handles, labels=['Does not end in period', 'Ends in period'], bbox_to_anchor=(1, 0.7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove repeated words\n",
    "(This was run preceding pilot3 on the timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in os.listdir('.'):\n",
    "#     if os.path.isdir(s):\n",
    "#         print(s)\n",
    "#         for seed in os.listdir(s):\n",
    "#             fname = os.path.join(s, seed, 'timings_processed.csv')\n",
    "#             t = pd.read_csv(fname)\n",
    "#             # remove rows with repeated word\n",
    "#             t = t[t['word'] != t['word'].shift(1)]\n",
    "#             t['time_running'] = np.cumsum(t[\"timing\"])\n",
    "#             t.to_csv(fname, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
