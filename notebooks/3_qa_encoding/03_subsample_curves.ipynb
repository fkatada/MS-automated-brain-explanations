{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from os.path import join\n",
    "# import config\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from neuro import analyze_helper, viz\n",
    "from neuro.features.feat_select import get_alphas\n",
    "import matplotlib.patches as mpatches\n",
    "import dvu\n",
    "from neuro import config\n",
    "import matplotlib\n",
    "dvu.set_style()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved out in main_curves nb\n",
    "data = joblib.load(join(config.RESULTS_DIR_LOCAL, 'results_best_ensemble.pkl'))\n",
    "r, cols_varied, mets = data['r'], data['cols_varied'], data['mets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r['qa_questions_version'] ==\n",
    "    'v3_boostexamples_merged']['weight_enet_mask_num_nonzero'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = rr\n",
    "r = r[r.qa_questions_version.isin(['', 'v3_boostexamples_merged'])]\n",
    "# r = r[r.feature_selection_alpha == -1]\n",
    "r = r[~r.feature_space.isin(\n",
    "    ['meta-llama/Llama-2-7b-hf', 'meta-llama/Meta-Llama-3-8B'])]\n",
    "cols_varied = [c for c in cols_varied if not c in [\n",
    "    'feature_selection_stability_seeds']]\n",
    "\n",
    "r = r[r.qa_embedding_model.isin(['', 'ensemble1', 'ensemble2'])]\n",
    "\n",
    "# only keep feature selection with stability\n",
    "r = r[(r.feature_selection_alpha < 0) | (\n",
    "    r.feature_selection_stability_seeds > 0)]\n",
    "\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check runs (full grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "# d = d[d.subject.isin(['S01', 'S02', 'S03'])]\n",
    "d = d[~(d.num_stories == 15)]\n",
    "# d = d[d.feature_selection_alpha < 0]\n",
    "d = d[\n",
    "    (d.feature_selection_alpha < 0) |\n",
    "    ((d.feature_space_simplified == 'qa_embedder')\n",
    "     & (d.feature_selection_alpha == get_alphas('qa_embedder')[3]))\n",
    "]\n",
    "d = d.groupby(cols_varied)[['corrs_test_mean']].mean()\n",
    "cols_top = ['feature_space', 'embedding_layer',\n",
    "            'qa_embedding_model', 'qa_questions_version', 'feature_selection_alpha']\n",
    "d = (\n",
    "    d.pivot_table(index=[c for c in cols_varied if not c in cols_top],\n",
    "                  columns=cols_top, values='corrs_test_mean', aggfunc='mean')\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "display(\n",
    "    d.style\n",
    "    .background_gradient(cmap='viridis', axis=1)\n",
    "    .format(precision=3)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check simplified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.feature_space.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.feature_space_simplified.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "d.num_stories = d.num_stories.replace(-1, 100)\n",
    "num_stories_list = [5, 10, 20, 100]\n",
    "d = d[d.num_stories.isin(num_stories_list)]\n",
    "# d = d[d.num_stories == 10]\n",
    "# d = d[d.subject.isin(['S01', 'S02', 'S03'])]\n",
    "# d = d[~d.subject.isin(['S01', 'S02', 'S03'])]\n",
    "d = d[\n",
    "    (d.feature_selection_alpha < 0) |\n",
    "    ((d.feature_space_simplified == 'qa_embedder')\n",
    "     & (d.feature_selection_alpha == get_alphas('qa_embedder')[3]))\n",
    "]\n",
    "group_cols = ['subject', 'num_stories',\n",
    "              'feature_space_simplified', 'feature_selection_alpha']\n",
    "metric_sort = 'corrs_tune_pc_weighted_mean'\n",
    "d = d.sort_values(\n",
    "    by=metric_sort, ascending=False)\n",
    "\n",
    "d = d.groupby(group_cols)[mets]\n",
    "d = d.first().reset_index()\n",
    "cols_top = ['feature_space_simplified', 'feature_selection_alpha']\n",
    "d_tab = (\n",
    "    d.pivot_table(index=[c for c in group_cols if not c in cols_top],\n",
    "                  columns=cols_top, values='corrs_test_mean', aggfunc='mean')\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "display(\n",
    "    d_tab.style\n",
    "    .background_gradient(cmap='magma', axis=1)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_all_qa_100 = d_tab[('qa_embedder', 0.28)][np.array([x[1]\n",
    "                                                        for x in d_tab.index]) == 100].mean()\n",
    "val_all_llama_100 = d_tab[('llama', -1.0)][np.array([x[1]\n",
    "                                                     for x in d_tab.index]) == 100].mean()\n",
    "print(f'val_all_qa_100: {val_all_qa_100:.3f} val_all_llama_100: {val_all_llama_100:.3f} improvement: {(val_all_qa_100 - val_all_llama_100) / val_all_llama_100:.2%}')\n",
    "\n",
    "val_all_qa_10 = d_tab[('qa_embedder', 0.28)][np.array([x[1]\n",
    "                                                       for x in d_tab.index]) == 5].mean()\n",
    "val_all_llama_10 = d_tab[('llama', -1.0)][np.array([x[1]\n",
    "                                                    for x in d_tab.index]) == 5].mean()\n",
    "print(f'val_all_qa_10: {val_all_qa_10:.3f} val_all_llama_10: {val_all_llama_10:.3f} improvement: {(val_all_qa_10 - val_all_llama_10) / val_all_llama_10:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make subsample barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "d['legend'] = list(\n",
    "    zip(d.feature_space_simplified.map(viz.feature_space_rename), d.feature_selection_alpha))\n",
    "# ('BERT', -1.0), ('Eng1000', -1.0), ('LLaMA', -1.0),\n",
    "#    ('QA-Emb', -1.0), ('QA-Emb', 0.28)\n",
    "d['legend'] = d['legend'].map(lambda x: {\n",
    "    ('BERT', -1.0): 'BERT',\n",
    "    ('Eng1000', -1.0): 'Eng1000',\n",
    "    ('LLaMA', -1.0): 'LLaMA (best)',\n",
    "    ('QA-Emb', -1.0): 'QA',\n",
    "    ('QA-Emb', 0.28): 'QA (35 questions)'\n",
    "}.get(x, x))\n",
    "kwargs = dict(\n",
    "    x='num_stories',\n",
    "    y='corrs_test_mean',\n",
    "    hue='legend',\n",
    "    hue_order=['Eng1000', 'BERT', 'LLaMA (best)', 'QA', 'QA (35 questions)'],\n",
    "    palette=['tomato', '#aaa', '#000', 'C0', 'cadetblue'],\n",
    "    dodge=True,\n",
    ")\n",
    "# sns.boxplot(**kwargs, fill=False)\n",
    "# fig = plt.figure(figsize=(12, 6))\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.figure(dpi=300, figsize=(8, 4))\n",
    "ax = sns.barplot(**kwargs, data=d, alpha=0.2, errorbar='se',\n",
    "                 err_kws={'alpha': 0.4}, legend=False)\n",
    "sns.stripplot(\n",
    "    **kwargs, data=d[d.subject.isin(['S01', 'S02', 'S03'])], jitter=True, size=7, legend=False)\n",
    "# sns.stripplot(**kwargs, jitter=True, size=4)\n",
    "sns.stripplot(\n",
    "    **kwargs, data=d[~d.subject.isin(['S01', 'S02', 'S03'])], jitter=True, size=7)\n",
    "\n",
    "# ylim bottom to 0\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# replace \"100\" with \"All\" on xticklabels\n",
    "xtick_labels = ax.get_xticklabels()\n",
    "ax.set_xticklabels(['All' if label.get_text() ==\n",
    "                   '100' else label.get_text() for label in xtick_labels])\n",
    "\n",
    "plt.xlabel(\"Number of stories used for training\")\n",
    "plt.ylabel(\"Test correlation\")\n",
    "\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.legend(loc='upper left')  # , bbox_to_anchor=(1, 0.5))\n",
    "# viz.savefig('subsample/subsample_barplot.pdf', bbox_inches='tight')\n",
    "plt.savefig('subsample/subsample_barplot.png',\n",
    "            bbox_inches='tight', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.num_stories.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "dp = d[d.num_stories.isin([5, 100])]\n",
    "dp['legend'] = list(\n",
    "    zip(dp.feature_space_simplified.map(viz.feature_space_rename), dp.feature_selection_alpha))\n",
    "# ('BERT', -1.0), ('Eng1000', -1.0), ('LLaMA', -1.0),\n",
    "#    ('QA-Emb', -1.0), ('QA-Emb', 0.28)\n",
    "dp['legend'] = dp['legend'].map(lambda x: {\n",
    "    ('BERT', -1.0): 'BERT',\n",
    "    ('Eng1000', -1.0): 'Eng1000',\n",
    "    ('LLaMA', -1.0): 'LLaMA (best)',\n",
    "    ('QA-Emb', -1.0): 'QA',\n",
    "    ('QA-Emb', 0.28): 'QA (35 questions)'\n",
    "}.get(x, x))\n",
    "kwargs = dict(\n",
    "    x='num_stories',\n",
    "    y='corrs_test_mean',\n",
    "    hue='legend',\n",
    "    hue_order=['Eng1000', 'BERT', 'LLaMA (best)', 'QA', 'QA (35 questions)'],\n",
    "    palette=['tomato', '#aaa', '#000', 'C0', 'navy'],\n",
    "    dodge=True,\n",
    ")\n",
    "# sns.boxplot(**kwargs, fill=False)\n",
    "# fig = plt.figure(figsize=(12, 6))\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.figure(dpi=300, figsize=(8, 4))\n",
    "ax = sns.barplot(**kwargs, data=dp, legend=True, errorbar=None)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "xtick_labels = ax.get_xticklabels()\n",
    "ax.set_xticklabels(['All' if label.get_text() ==\n",
    "                   '100' else label.get_text() for label in xtick_labels])\n",
    "\n",
    "plt.xlabel(\"Number of stories used for training\")\n",
    "plt.ylabel(\"Predictive performance\")\n",
    "\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.legend(loc='upper left')  # , bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig('subsample/subsample_barplot.pdf', bbox_inches='tight')\n",
    "plt.savefig('subsample/subsample_barplot.png',\n",
    "            bbox_inches='tight', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stories_list = [5, 10, 20, 100]\n",
    "dt = d_tab.reset_index()\n",
    "for i, num_stories in enumerate(num_stories_list):\n",
    "    dn = dt[dt.num_stories == num_stories]\n",
    "    # display(dn)\n",
    "    print(f'num_stories = {num_stories}')\n",
    "    display(dn.drop(columns=['num_stories']).style.background_gradient(\n",
    "        cmap='magma', axis=1).format(precision=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
