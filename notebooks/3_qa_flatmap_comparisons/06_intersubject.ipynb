{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from math import ceil\n",
    "import cortex\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import gct\n",
    "from neuro.flatmaps_helper import load_flatmaps\n",
    "import neuro.sasc.viz\n",
    "from neuro import analyze_helper, config\n",
    "from joblib import Memory\n",
    "\n",
    "import nibabel as nib\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import neurosynth\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "import viz\n",
    "config.setup_freesurfer()\n",
    "\n",
    "subject = 'S02'\n",
    "# subjects = [f'S0{i}' for i in range(1, 9) if not i == 6] # there's some problem with S06 surf2surf\n",
    "subjects = ['S01', 'S02', 'S03']\n",
    "\n",
    "# load flatmaps\n",
    "d = defaultdict(list)\n",
    "for subject in subjects:\n",
    "    # if subject in ['S01', 'S02', 'S03']:\n",
    "    # settings = ['individual_gpt4',\n",
    "    # 'individual_gpt4_wordrate', 'shapley_35']\n",
    "    # else:\n",
    "    # settings = ['individual_gpt4_ndel=1_pc_new']\n",
    "    settings = ['individual_gpt4_pc_new']\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(config.PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()\n",
    "    }\n",
    "    # for k in sorted(flatmaps_qa_dict.keys()):\n",
    "    for k in QS_35_STABLE:\n",
    "        # print(k, flatmaps_qa_dict[k])\n",
    "        # d[f'q_{subject}'].append(k)\n",
    "        d[subject].append(flatmaps_qa_dict[k])\n",
    "\n",
    "    # print(subject, len(flatmaps_qa_dict))\n",
    "df = pd.DataFrame(d)\n",
    "# df.set_index('q_S01', inplace=True)\n",
    "df.index = QS_35_STABLE\n",
    "df.index.name = 'question'\n",
    "df = df[df.index.isin(QS_35_STABLE)]\n",
    "assert df.shape[0] == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save mni vols\n",
    "# mni_arrs_list = []\n",
    "# for q in tqdm(df.index):\n",
    "#     mni_vols = []\n",
    "#     for subject in subjects:\n",
    "#         print(subject)\n",
    "#         subj_vol = cortex.Volume(df.loc[q][subject], 'UT' + subject,\n",
    "#                                  xfmname=f\"UT{subject}_auto\")\n",
    "#         mni_vol = neurosynth.subj_vol_to_mni_surf(subj_vol, subject)\n",
    "#         mni_vols.append(deepcopy(mni_vol))\n",
    "#         mni_arrs = [mni_vol.data for mni_vol in mni_vols]\n",
    "#     mni_arrs_list.append(deepcopy(mni_arrs))\n",
    "# joblib.dump(mni_arrs_list, 'intersubject/mni_arrs_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(location=\"intersubject/mni_cache\", verbose=0)\n",
    "\n",
    "\n",
    "# load arrs for first 3 subjects\n",
    "mni_arrs_list = joblib.load('intersubject/mni_arrs_list.pkl')\n",
    "mni_arrs_list = [a[:3] for a in mni_arrs_list]\n",
    "subjects = subjects[:3]\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def mni_arr_subj_arr_cachable(mni_arr, subject):\n",
    "    mni_vol = cortex.Volume(mni_arr, \"fsaverage\", \"atlas_2mm\")\n",
    "    subj_vol, subj_arr = neurosynth.mni_vol_to_subj_vol_surf(mni_vol, subject)\n",
    "    return subj_arr\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def subj_arr_subj_arr_cachable(subj_arr, subject_input, subject_target):\n",
    "    print('args', subj_arr.shape, subject_input, subject_target)\n",
    "    subj_vol = cortex.Volume(subj_arr, subject='UT' + subject_input,\n",
    "                             xfmname=f\"UT{subject_input}_auto\")\n",
    "    return neurosynth.subj_vol_to_subj_surf(\n",
    "        subj_vol, subject_input, subject_target)\n",
    "\n",
    "\n",
    "# compute correlations\n",
    "corrs_list = []\n",
    "corrs_list_subj = []\n",
    "corrs_list_subj_direct = []\n",
    "for j, q in enumerate(df.index):\n",
    "    # compute correlation between each one and mean of the others\n",
    "    mni_arrs = np.array(mni_arrs_list[j])\n",
    "    corrs_loo = []\n",
    "    corrs_loo_subj = []\n",
    "    corrs_loo_subj_direct = []\n",
    "    for i, subj in enumerate(subjects):\n",
    "        mni_arr = mni_arrs[i]\n",
    "        subj_arr = df.loc[q][subj]\n",
    "        other_mni_arrs = np.delete(mni_arrs, i, axis=0)\n",
    "        mean_other_mni_arr = np.mean(other_mni_arrs, axis=0)\n",
    "\n",
    "        # corr = np.corrcoef(mni_arr.flatten(),\n",
    "        #                    mean_other_mni_arr.flatten())[0, 1]\n",
    "        # print(f'mni corr between {i} and mean of others', corr)\n",
    "        # corrs_loo.append(corr)\n",
    "\n",
    "        mean_other_subj_arr = mni_arr_subj_arr_cachable(\n",
    "            mean_other_mni_arr, subj)\n",
    "        corr_subj = np.corrcoef(subj_arr.flatten(),\n",
    "                                mean_other_subj_arr.flatten())[0, 1]\n",
    "        print(f'subj corr between {i} and mean of others', corr_subj)\n",
    "        corrs_loo_subj.append(corr_subj)\n",
    "\n",
    "        other_subj_arrs = [\n",
    "            subj_arr_subj_arr_cachable(\n",
    "                df.loc[q][subj_input], subj_input, subject_target=subj)\n",
    "            for subj_input in subjects if not subj_input == subj\n",
    "        ]\n",
    "        mean_other_subj_arr = np.mean(other_subj_arrs, axis=0)\n",
    "        corr_subj_direct = np.corrcoef(subj_arr.flatten(),\n",
    "                                       mean_other_subj_arr.flatten())[0, 1]\n",
    "        print(\n",
    "            f'subj dir corr between {i} and mean of others', corr_subj_direct)\n",
    "        corrs_loo_subj_direct.append(corr_subj_direct)\n",
    "\n",
    "    corrs_list.append(corrs_loo)\n",
    "    corrs_list_subj.append(corrs_loo_subj)\n",
    "    corrs_list_subj_direct.append(corrs_loo_subj_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrs_df = pd.DataFrame(np.array(corrs_list), columns=subjects, index=df.index)\n",
    "# corrs_df = pd.DataFrame(np.array(corrs_list_subj_direct),\n",
    "# columns=subjects, index=df.index)\n",
    "corrs_df = pd.DataFrame(np.array(corrs_list_subj),\n",
    "                        columns=subjects, index=df.index)\n",
    "corrs_df.to_pickle('corrs_df/intersubject.pkl')\n",
    "\n",
    "# flatten with column name as value for a new column\n",
    "corrs_df = corrs_df.melt(\n",
    "    ignore_index=False, var_name='subject', value_name='corrs').reset_index()\n",
    "corrs_df.rename(columns={'question': 'questions'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(11, 6), dpi=300)\n",
    "neurosynth_compare.plot_corrs_df(\n",
    "    corrs_df,\n",
    "    out_dir='intersubject',\n",
    "    plot_val=f'corrs',\n",
    "    xlab=f'Inter-subject correlation\\n(Each subject vs. the average of the other two)',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.DataFrame(np.array(corrs_list_subj),\n",
    "                        columns=subjects, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_distrs = []\n",
    "# for i, subject in enumerate(tqdm(['UTS01', 'UTS02', 'UTS03'])):\n",
    "#     flatmaps_qa_list = [arr[i].flatten() for arr in mni_arrs_list]\n",
    "#     flatmaps_null = np.array(joblib.load(\n",
    "#         join(PROCESSED_DIR,\n",
    "#              #  subject.replace('UT', ''), 'resp_chunks_1trs.pkl')))\n",
    "#              subject.replace('UT', ''), 'resp_chunks_1trs_MNI.pkl')))\n",
    "#     # flatmaps_null = [arr.flatten() for arr in flatmaps_null]\n",
    "#     flatmaps_null = flatmaps_null.reshape(flatmaps_null.shape[0], -1)\n",
    "\n",
    "#     _, baseline_distr = viz.compute_pvals(\n",
    "#         flatmaps_qa_list,\n",
    "#         frac_voxels_to_keep=1,\n",
    "#         corrs_gt_arr=corrs_df[f'corrs'].values,\n",
    "#         flatmaps_null=flatmaps_null,\n",
    "#     )\n",
    "\n",
    "#     baseline_distrs.append(baseline_distr)\n",
    "# joblib.dump(baseline_distrs, 'baseline_distrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distrs = joblib.load('baseline_distrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_baseline = np.array(baseline_distrs).mean(axis=0)\n",
    "vals_alt = corrs_df[f'corrs'].values\n",
    "\n",
    "n = len(vals_alt)\n",
    "print(np.mean(vals_alt))\n",
    "\n",
    "# permutation test on mean\n",
    "n_samples = 1000\n",
    "means_baseline = [\n",
    "    np.mean(np.random.choice(vals_baseline.flatten(), size=n, replace=False))\n",
    "    for i in range(n_samples)\n",
    "]\n",
    "print('mean test p', np.mean(np.array(means_baseline) >= np.mean(vals_alt)))\n",
    "\n",
    "# permutation test on individuals\n",
    "pvals = []\n",
    "for i in range(len(vals_baseline)):\n",
    "    pvals.append(np.mean(vals_baseline[i] >= vals_alt[i]))\n",
    "pvals = multipletests(\n",
    "    pvals, method='fdr_bh', alpha=0.05)[1]\n",
    "print('individual pvals (err corrected)',\n",
    "      pvals, 'num sig', np.sum(pvals < 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export mean mni arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_arr_mean_dict = {\n",
    "    k: np.mean(v, axis=0) for k, v in zip(df.index, mni_arrs_list)\n",
    "}\n",
    "joblib.dump(mni_arr_mean_dict,\n",
    "            'intersubject/mni_arr_mean_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mni_arr_mean_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mni_arr_mean_dict.values())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = joblib.load('intersubject/mni_arr_mean_dict.pkl')\n",
    "# d['Does the sentence describe a personal reflection or thought?'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rclone copy /home/chansingh/fmri/notebooks_gt_flatmaps/intersubject/mni_arr_mean_dict.pkl box:DeepTune/QA/flatmaps_mni --progress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
