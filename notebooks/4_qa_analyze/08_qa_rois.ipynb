{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/chansingh/.venv/lib/python3.12/site-packages/cortex/mni.py:21: UserWarning: Can't find FSLDIR environment variable, assuming default FSL location..\n",
      "  warnings.warn(\"Can't find FSLDIR environment variable, assuming default FSL location..\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import dvu\n",
    "from copy import deepcopy\n",
    "import neuro.viz\n",
    "import sys\n",
    "from numpy import ceil\n",
    "from matplotlib.colors import ListedColormap\n",
    "sys.path.append('../notebooks')\n",
    "from tqdm import tqdm\n",
    "from neuro import config\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "import neuro.sasc.viz\n",
    "from PIL import Image\n",
    "# from flatmaps_helper import VOX_COUNTS, load_custom_rois, ROI_EXPLANATIONS_S03, FED_DRIVING_EXPLANATIONS_S03, FED_DRIVING_EXPLANATIONS_S02\n",
    "from neuro.flatmaps_helper import load_flatmaps, load_custom_rois, load_known_rois\n",
    "import neuro.flatmaps_helper\n",
    "import sys\n",
    "from neuro import analyze_helper\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import neurosynth\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'S02'\n",
    "# subjects = [f'S0{i}' for i in range(1, 9) if not i == 6] # there's some problem with S06 surf2surf\n",
    "subjects = ['S01', 'S02', 'S03', 'S08']\n",
    "\n",
    "# load flatmaps\n",
    "d = defaultdict(list)\n",
    "for subject in subjects:\n",
    "    # if subject in ['S01', 'S02', 'S03']:\n",
    "    # settings = ['individual_gpt4',\n",
    "    # 'individual_gpt4_wordrate', 'shapley_35']\n",
    "    # else:\n",
    "    settings = ['individual_gpt4_pc_new']\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(config.PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()\n",
    "    }\n",
    "    # for k in sorted(flatmaps_qa_dict.keys()):\n",
    "    for k in QS_35_STABLE:\n",
    "        # print(k, flatmaps_qa_dict[k])\n",
    "        # d[f'q_{subject}'].append(k)\n",
    "        d[subject].append(flatmaps_qa_dict[k])\n",
    "\n",
    "    # print(subject, len(flatmaps_qa_dict))\n",
    "df = pd.DataFrame(d)\n",
    "# df.set_index('q_S01', inplace=True)\n",
    "df.index = QS_35_STABLE\n",
    "df.index.name = 'question'\n",
    "df = df[df.index.isin(QS_35_STABLE)]\n",
    "assert df.shape[0] == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load(join(config.RESULTS_DIR_LOCAL, 'results_best_ensemble.pkl'))\n",
    "rr, cols_varied, mets = data['r'], data['cols_varied'], data['mets']\n",
    "metric_sort = 'corrs_tune_pc_weighted_mean'\n",
    "rr_best = rr[(rr.pc_components == 100) *\n",
    "             (rr.ndelays == 8) *\n",
    "             (rr.feature_space.str.contains('qa_emb')) *\n",
    "             (rr.feature_selection_alpha < 0) *\n",
    "             (rr.num_stories == -1) *\n",
    "             (rr.qa_embedding_model == 'ensemble2')\n",
    "             ]  # .sort_values(by='corrs_test_mean').iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select avg-response flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select\n",
    "avg_defaultdict = defaultdict(list)\n",
    "for subject in ['S01', 'S02', 'S03']:  # , 'S02']:\n",
    "    qa_flatmaps_dict = df[subject].to_dict()\n",
    "\n",
    "    # rois_dict = neuro.flatmaps_helper.load_known_rois(subject)\n",
    "    rois_dict = neuro.flatmaps_helper.load_custom_rois(\n",
    "        subject, suffix_setting='_lobes')\n",
    "\n",
    "    corrs_35 = rr_best[rr_best.subject == subject]['corrs_test'].iloc[0]\n",
    "    sig_well_predicted = corrs_35 > 0.1\n",
    "    # for k in rois_dict.keys():\n",
    "    # rois_dict[subject + ' lang\\n(ρ>0.1)'] = sig_well_predicted & sig\n",
    "    # rois_dict[subject + ' non-lang\\n(ρ>0.1)'] = sig_well_predicted & ~sig\n",
    "\n",
    "    ##################################################\n",
    "    # compute means\n",
    "    # avg_defaultdict = defaultdict(list)\n",
    "    for i, (roi_idx, roi) in enumerate(rois_dict.items()):\n",
    "        for explanation in qa_flatmaps_dict.keys():\n",
    "            avg_defaultdict[roi_idx].append(\n",
    "                np.mean(qa_flatmaps_dict[explanation][roi > 0]))\n",
    "            if i == 0:\n",
    "                avg_defaultdict['subject'].append(subject)\n",
    "                avg_defaultdict['explanation'].append(explanation)\n",
    "            # corrs_defaultdict[roi_idx].append(\n",
    "            # np.corrcoef(roi, gemv_flatmaps_dict[explanation])[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(avg_defaultdict)  # .set_index(['explanation'])\n",
    "d = d.drop(columns='subject').groupby('explanation').mean()\n",
    "d.index = [analyze_helper.abbrev_question(q) for q in d.index]\n",
    "d.columns = [c.capitalize() for c in d.columns]\n",
    "vabs = max(abs(d.values.min()), abs(d.values.max()))\n",
    "\n",
    "g = sns.clustermap(d, annot=False, fmt='.3f', cmap='RdBu_r', center=0, vmin=-vabs, vmax=vabs,\n",
    "               annot_kws={\"size\": 10}, cbar_kws={\"label\": \"Average QA weight\"}, linewidths=.5,\n",
    "               )\n",
    "# reverse order of rows\n",
    "g.ax_heatmap.invert_yaxis()\n",
    "\n",
    "g.ax_row_dendrogram.set_visible(False)\n",
    "g.ax_col_dendrogram.set_visible(False)\n",
    "g.ax_heatmap.set_xlabel('Cortical region or lobe')\n",
    "cbar = g.ax_heatmap.collections[0].colorbar\n",
    "cbar.remove()\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=90, ha='right', fontsize=10)\n",
    "\n",
    "# tick left\n",
    "yticklabels = g.ax_heatmap.get_yticklabels()\n",
    "# Remove the default left-side ticks\n",
    "g.ax_heatmap.yaxis.tick_left()\n",
    "g.ax_heatmap.yaxis.set_label_position('right')\n",
    "for label in yticklabels:\n",
    "    label.set_ha('right')\n",
    "    label.set_x(-0.12)  \n",
    "\n",
    "# assign color\n",
    "q_to_idx = {analyze_helper.abbrev_question(q): i for (q,i) in viz.REMAP_QUESTIONS_TO_CATEGORY_IDXS.items()}\n",
    "tab10 = plt.get_cmap('tab10')\n",
    "n_colors = len(set(q_to_idx.values()))\n",
    "colors = [tab10(i) for i in range(n_colors)]\n",
    "\n",
    "for ticklabel in g.ax_heatmap.get_yticklabels():\n",
    "    # ticklabel.set_color((random.random(), random.random(), random.random()))\n",
    "    ticklabel.set_color(colors[q_to_idx[ticklabel.get_text()]])\n",
    "joblib.dump([x.get_text() for x in g.ax_heatmap.get_yticklabels()], 'qa_rois/qa_rois_qnames_abbreviated_list.pkl')\n",
    "\n",
    "plt.gcf().set_size_inches(4.1, 9)\n",
    "# plt.show()\n",
    "neuro.viz.savefig('qa_rois/qa_rois_matrix.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make top-voxel fig\n",
    "(based on QA-35 coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'S02'\n",
    "use_abs = True\n",
    "if use_abs:\n",
    "    vals = df[subject].abs().values\n",
    "else:\n",
    "    vals = df[subject].values\n",
    "top_q_flatmap = np.vstack(vals).argmax(axis=0).astype(float)\n",
    "corrs_35 = rr_best[rr_best.subject == subject]['corrs_test'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrs_35 = rr_best[rr_best.subject == subject]['corrs_test'].iloc[0]\n",
    "# sig_well_predicted = corrs_35 > 0.1\n",
    "# top_q_flatmap[~sig_well_predicted] = np.nan\n",
    "# neuro.viz.quickshow(top_q_flatmap, subject=subject, cmap='tab10', center=False)\n",
    "\n",
    "top_q_flatmap_remapped = deepcopy(top_q_flatmap)\n",
    "for category_name, v in viz.REMAP_CATEGORY_TO_QUESTIONS.items():\n",
    "    num_new = v[0]\n",
    "    remap_nums = v[1]\n",
    "    for num_old in remap_nums.keys():\n",
    "        top_q_flatmap_remapped[top_q_flatmap == num_old] = num_new\n",
    "\n",
    "# sig_well_predicted = corrs_35 > 0.15\n",
    "# top_q_flatmap_remapped[~sig_well_predicted] = np.nan\n",
    "\n",
    "n_colors = len(np.unique(top_q_flatmap_remapped[~np.isnan(top_q_flatmap_remapped)]))\n",
    "tab10 = plt.get_cmap('tab10')\n",
    "colors = [tab10(i) for i in range(n_colors)]\n",
    "# colors = sns.color_palette(\"deep\", as_cmap=True)\n",
    "# cmap = ListedColormap(colors)\n",
    "# cmap.set_bad(color='none')  # For fully transparent, use 'none'\n",
    "\n",
    "# map top_q_flatmap_remapped into rgb array using cmap\n",
    "# top_q_flatmap_rgb = cmap(top_q_flatmap_remapped / n_colors)\n",
    "top_q_flatmap_rgb = [colors[int(i)] if not np.isnan(i) else (1, 1, 1, 0) for i in top_q_flatmap_remapped]\n",
    "top_q_flatmap_rgb = np.array(top_q_flatmap_rgb)\n",
    "\n",
    "alpha = corrs_35\n",
    "alpha[alpha < 0] = 0  # Set negative values to 0\n",
    "alpha = (alpha - alpha.min()) / (alpha.max() - alpha.min())\n",
    "\n",
    "vol = cortex.VolumeRGB(\n",
    "    top_q_flatmap_rgb[:, 0].flatten(), top_q_flatmap_rgb[:, 1].flatten(), top_q_flatmap_rgb[:, 2].flatten(),\n",
    "    subject='UT' + subject, xfmname=f'UT{subject}_auto', alpha=alpha) #, cmap=cmap)\n",
    "\n",
    "neuro.viz.quickshow(vol, with_colorbar=False,\n",
    "    fname_save=f'qa_rois/qa_rois_flatmap_{subject}_abs={use_abs}.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_q_flatmap_remapped_masked = top_q_flatmap_remapped.astype(float)\n",
    "# top_q_flatmap_remapped_masked[corrs_35 < 0.1] = np.nan\n",
    "# neuro.viz.quickshow(\n",
    "#     top_q_flatmap_remapped_masked.astype(int),\n",
    "#     subject='UTS02',\n",
    "#     cmap=len(np.unique(top_q_flatmap_remapped_masked)),\n",
    "#     center=False,\n",
    "#     with_colorbar=False,\n",
    "#     fname_save='qa_rois_flatmap_masked.png',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(corrs_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save color pallete as a colorbar\n",
    "plt.figure(figsize=(10, 2))\n",
    "sns.palplot(sns.color_palette(\"husl\", 5))\n",
    "plt.axis('off')\n",
    "# add labels\n",
    "for i, category_name in enumerate(remap.keys()):\n",
    "    plt.text(i + 0.1, 0.5, category_name,\n",
    "             ha='center', va='center', fontsize=12, rotation=45)\n",
    "plt.savefig('qa_rois_flatmap_palette.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
