{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import sasc.config\n",
    "from sasc import config\n",
    "import numpy as np\n",
    "import sasc.viz\n",
    "from sasc import analyze_helper\n",
    "from sasc.config import FMRI_DIR, RESULTS_DIR\n",
    "import dvu\n",
    "import pandas as pd\n",
    "dvu.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pilot pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# pilot_name = 'pilot_story_data.pkl'\n",
    "# pilot_name = 'pilot3_story_data.pkl'\n",
    "pilot_name = 'pilot4_story_data.pkl'\n",
    "# pilot_name = 'pilot5_story_data.pkl'\n",
    "stories_data_dict = joblib.load(\n",
    "    join(config.RESULTS_DIR, 'processed', pilot_name))\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20230504')\n",
    "elif pilot_name == 'pilot3_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20231106')\n",
    "elif pilot_name == 'pilot4_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20240509')\n",
    "elif pilot_name == 'pilot5_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20240604')\n",
    "\n",
    "# load responses\n",
    "# story_idxs = np.where(\n",
    "    # np.array(stories_data_dict['story_setting']) == 'default')[0]\n",
    "story_idxs = np.arange(len(stories_data_dict['story_name_new']))\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings_list = stories_data_dict['timing']\n",
    "story_names_list = list(resps_dict.keys())\n",
    "resps = list(resps_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeptune-story19.npy resp_length 372 story_text_trs 376±1\n",
      "\t(abs(diff - TRIM * 2))=6\n",
      "deeptune-story20.npy resp_length 391 story_text_trs 395±1\n",
      "\t(abs(diff - TRIM * 2))=6\n",
      "deeptune-story21.npy resp_length 438 story_text_trs 442±1\n",
      "\t(abs(diff - TRIM * 2))=6\n",
      "deeptune-story22.npy resp_length 355 story_text_trs 359±1\n",
      "\t(abs(diff - TRIM * 2))=6\n"
     ]
    }
   ],
   "source": [
    "TRIM = 5\n",
    "for i in range(len(resps)):\n",
    "    t = timings_list[i]\n",
    "    duration_secs = t['time_running'].max()\n",
    "    print(story_names_list[i], 'resp_length',\n",
    "          resps[i].shape[0],\n",
    "          'story_text_trs', str(int(duration_secs // 2)) + '±1')  # , 'timings',\n",
    "    diff = int(duration_secs // 2) - resps[i].shape[0]\n",
    "    print(f'\\t{(abs(diff - TRIM * 2))=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the alignment w/ paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for story_num in [0]:\n",
    "for story_num in story_idxs:\n",
    "    rows = stories_data_dict[\"rows\"][story_num]\n",
    "\n",
    "    # get resp_chunks\n",
    "    resp_story = resps_dict[\n",
    "        stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "            '_resps', '')\n",
    "    ].T  # (voxels, time)\n",
    "    timing = stories_data_dict[\"timing\"][story_num]\n",
    "    if 'paragraphs' in stories_data_dict.keys():\n",
    "        paragraphs = stories_data_dict[\"paragraphs\"][story_num]\n",
    "    else:\n",
    "        paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "\n",
    "    if pilot_name in ['pilot3_story_data.pkl']:\n",
    "        paragraphs = [sasc.analyze_helper.remove_repeated_words(\n",
    "            p) for p in paragraphs]\n",
    "    assert len(paragraphs) == len(rows), f\"{len(paragraphs)} != {len(rows)}\"\n",
    "    resp_chunks = analyze_helper.get_resps_for_paragraphs(\n",
    "        timing, paragraphs, resp_story, offset=2)\n",
    "    assert len(resp_chunks) <= len(\n",
    "        paragraphs), f\"{len(resp_chunks)} > {len(paragraphs)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_indexes, end_indexes \u001b[38;5;241m=\u001b[39m analyze_helper\u001b[38;5;241m.\u001b[39mget_start_end_indexes_for_paragraphs(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtiming\u001b[49m, paragraphs)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(paragraphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(timing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timing' is not defined"
     ]
    }
   ],
   "source": [
    "start_indexes, end_indexes = analyze_helper.get_start_end_indexes_for_paragraphs(\n",
    "    timing, paragraphs)\n",
    "print(paragraphs[0].split())\n",
    "print(timing['word'].values.tolist())\n",
    "print(\n",
    "    f'should have {len(paragraphs)} paragraphs but only found {len(resp_chunks)}')\n",
    "for i in range(min(len(paragraphs), len(start_indexes))):\n",
    "    print(i, '\\t', len(paragraphs[i].split()),\n",
    "          '\\t', end_indexes[i] - start_indexes[i])\n",
    "    # print(i, timing['word'].values.tolist()[start_indexes[i]:end_indexes[i]])\n",
    "    # print(i, resp_chunks[i].shape)\n",
    "# print([len(p.split()) for p in paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As I stood there, lost in my thoughts about the various aspects of my life that had been influenced by age, locations, experiences, and relationships, I couldn't help but notice how quickly time seemed to pass. It felt like just yesterday when, weeks earlier, I had embarked on a new adventure that had challenged me to step out of my comfort zone and embrace the unknown. Weeks later, I found myself reflecting on the lessons I had learned and the memories I had created during that time. And just a few weeks later, it was time for me to embark on yet another journey, one that would undoubtedly bring new challenges and opportunities for growth. With each passing week, I became more aware of the precious nature of time and the importance of making the most of each moment. As I continued to grow older, I was determined to live a life filled with love, laughter, and meaningful experiences that would stand the test of time.\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# note: final paragraph of story wasn't run\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(paragraphs)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m i \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mindex(\u001b[39m'\u001b[39;49m\u001b[39mthick and thin,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m i_final_paragraph \u001b[39m=\u001b[39m x[i:]\u001b[39m.\u001b[39mindex(\u001b[39m'\u001b[39m\u001b[39mAs the couple\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m x[i \u001b[39m+\u001b[39m i_final_paragraph:]\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "# note: final paragraph of story wasn't run\n",
    "x = '\\n'.join(paragraphs)\n",
    "i = x.index('thick and thin,')\n",
    "i_final_paragraph = x[i:].index('As the couple')\n",
    "x[i + i_final_paragraph:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
