{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandan/code/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chansingh/mntv1/deep-fMRI/sasc/rj_models/voxel_lists/UTS01_voxel_selectivity.jbl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# import story_helper\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msasc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmri_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_module_num_to_voxel_num, add_stability_score\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msasc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FMRI_DIR, STORIES_DIR\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msasc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "File \u001b[0;32m~/code/automated-explanations/sasc/modules/fmri_module.py:32\u001b[0m\n\u001b[1;32m     26\u001b[0m NUM_TOP_VOXELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mWhen adding a new model, need to:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m- run cache_preprocessor() on the extracted features\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m VOXELS_IDXS_DICT \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVE_DIR_FMRI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoxel_lists\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubject\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_voxel_selectivity.jbl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUTS01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUTS02\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUTS03\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m}\u001b[49m\n\u001b[1;32m     39\u001b[0m STABILITY_SCORES_DICT \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     40\u001b[0m     join(RESULTS_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msasc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmri_stability_scores.jbl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_module_num_to_voxel_num\u001b[39m(module_num: \u001b[38;5;28mint\u001b[39m, subject: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/code/automated-explanations/sasc/modules/fmri_module.py:33\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m NUM_TOP_VOXELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mWhen adding a new model, need to:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m- run cache_preprocessor() on the extracted features\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m VOXELS_IDXS_DICT \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 33\u001b[0m     subject: \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVE_DIR_FMRI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoxel_lists\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubject\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_voxel_selectivity.jbl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTS01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTS02\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTS03\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     39\u001b[0m STABILITY_SCORES_DICT \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     40\u001b[0m     join(RESULTS_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msasc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmri_stability_scores.jbl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_module_num_to_voxel_num\u001b[39m(module_num: \u001b[38;5;28mint\u001b[39m, subject: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.11/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/chansingh/mntv1/deep-fMRI/sasc/rj_models/voxel_lists/UTS01_voxel_selectivity.jbl'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "# import story_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num, add_stability_score\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR\n",
    "from sasc import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the info from stories into a single pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stuff\n",
    "# double check all of these, intro paragraph may be the same...\n",
    "output_file = join(sasc.config.RESULTS_DIR,\n",
    "                   'processed', \"pilot4_story_data.pkl\")\n",
    "story_mapping = {\n",
    "    'default/uts01___may9___seed=5_top1': 'deeptune-story19.npy',\n",
    "    'default/uts01___may9___seed=2_top2': 'deeptune-story20.npy',\n",
    "\n",
    "    'interactions/uts01___may9___seed=3_top1': 'deeptune-story21.npy',\n",
    "    'interactions/uts01___may9___seed=6_top2': 'deeptune-story22.npy',\n",
    "}\n",
    "\n",
    "# custom timings because the story had to be slowed down\n",
    "story_timings_custom = {\n",
    "    'default/uts01___may9___seed=5_top1': 'UTS01_deeptune19.report',\n",
    "    'default/uts01___may9___seed=2_top2': 'UTS01_deeptune20.report',\n",
    "\n",
    "    'interactions/uts01___may9___seed=3_top1': 'UTS01_deeptune21.report',\n",
    "    'interactions/uts01___may9___seed=6_top2': 'UTS01_deeptune22.report',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add header line to report files\n",
    "header_line = \"time misc word misc\"\n",
    "for val in story_timings_custom.values():\n",
    "    original_file = join(config.PILOT_STORY_DATA_DIR,\n",
    "                         '20240509', val)\n",
    "    new_file = join(config.PILOT_STORY_DATA_DIR,\n",
    "                    '20240509', val.replace('.report', '_processed.txt'))\n",
    "    with open(original_file, 'r') as file:\n",
    "        s = file.read()\n",
    "    with open(new_file, 'w') as file:\n",
    "        file.write(header_line + '\\n' + s.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune19_processed.txt\n",
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune20_processed.txt\n",
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune21_processed.txt\n",
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune22_processed.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chansingh/automated-explanations/results/processed/pilot4_story_data.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster_neighbors = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"cluster_neighbors_v1.pkl\"))\n",
    "perfs = joblib.load(join(sasc.config.FMRI_DIR, 'sasc', 'rj_models',\n",
    "                    'opt_model', 'new_setup_performance.jbl'))\n",
    "\n",
    "# add keys\n",
    "stories_data_dict = defaultdict(list)\n",
    "for story_idx, story_name in enumerate(story_mapping.keys()):\n",
    "    # add scalar story descriptions\n",
    "    stories_data_dict[\"story_name_original\"].append(story_name)\n",
    "    stories_data_dict[\"story_setting\"].append(story_name.split(\"/\")[0])\n",
    "    stories_data_dict[\"story_name_new\"].append(story_mapping[story_name])\n",
    "    stories_data_dict[\"story_text\"].append(\n",
    "        open(join(STORIES_DIR, story_name, \"story.txt\"), \"r\").read()\n",
    "    )\n",
    "    prompts_paragraphs = joblib.load(\n",
    "        join(STORIES_DIR, story_name, \"prompts_paragraphs.pkl\")\n",
    "    )\n",
    "\n",
    "    # add paragraph-level descriptions\n",
    "    timings_file = join(config.PILOT_STORY_DATA_DIR, '20240509',\n",
    "                        story_timings_custom[story_name]).replace('.report', '_processed.txt')\n",
    "    print(timings_file)\n",
    "    # , quotechar=None, quoting=3)\n",
    "    timings = pd.read_csv(timings_file, sep=' ')\n",
    "    timings = timings[timings.misc == 'word']\n",
    "    timings['time_running'] = timings['time']\n",
    "    timings = timings.reset_index()\n",
    "\n",
    "    timings_to_save = timings.copy()\n",
    "    # timings_to_save['time_running'] = timings_to_save['time_running'] - 10\n",
    "    timings_to_save['timing'] = np.diff(\n",
    "        timings_to_save['time_running']).tolist() + [0]\n",
    "\n",
    "    timings_to_save.to_csv(\n",
    "        join(STORIES_DIR, story_name, \"timings_processed_slowed.csv\")\n",
    "    )\n",
    "    # display(timings)\n",
    "    # timings['time_running'] = timings['time_running'] + 10\n",
    "\n",
    "    stories_data_dict[\"timing\"].append(\n",
    "        # pd.read_csv(join(STORIES_DIR, story_name, \"timings_processed.csv\"))\n",
    "        timings\n",
    "    )\n",
    "    stories_data_dict[\"prompts\"].append(prompts_paragraphs[\"prompts\"])\n",
    "    stories_data_dict[\"paragraphs\"].append(prompts_paragraphs[\"paragraphs\"])\n",
    "\n",
    "    # add paragraph-level metadata\n",
    "    # rows\n",
    "    # rows = pd.read_csv(join(STORIES_DIR, story_name, \"rows.csv\"))\n",
    "    story_metadata_per_paragraph = pd.read_pickle(\n",
    "        join(STORIES_DIR, story_name, \"rows.pkl\"))\n",
    "    story_metadata_per_paragraph[\"voxel_num\"] = story_metadata_per_paragraph.apply(\n",
    "        lambda row: convert_module_num_to_voxel_num(\n",
    "            row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    story_metadata_per_paragraph[\"stability_score\"] = story_metadata_per_paragraph.apply(\n",
    "        lambda row: add_stability_score(row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    story_metadata_per_paragraph = story_metadata_per_paragraph[\n",
    "        [\n",
    "            \"expl\",\n",
    "            \"module_num\",\n",
    "            \"top_explanation_init_strs\",\n",
    "            \"subject\",\n",
    "            \"fmri_test_corr\",\n",
    "            \"stability_score\",\n",
    "            # \"top_score_synthetic\",\n",
    "            \"top_score_normalized\",\n",
    "            \"roi_anat\",\n",
    "            \"roi_func\",\n",
    "            \"voxel_num\",\n",
    "        ]\n",
    "    ]\n",
    "    story_metadata_per_paragraph['test_corr_new'] = story_metadata_per_paragraph['voxel_num'].apply(\n",
    "        lambda x: perfs[x])\n",
    "    # rows['cluster_nums'] = rows['voxel_num'].map(cluster_neighbors)\n",
    "    stories_data_dict[\"rows\"].append(story_metadata_per_paragraph)\n",
    "\n",
    "    if \"interactions\" in list(story_mapping.keys())[story_idx]:\n",
    "        rows1 = pd.read_pickle(join(STORIES_DIR, story_name, \"rows1.pkl\"))\n",
    "        rows2 = pd.read_pickle(join(STORIES_DIR, story_name, \"rows2.pkl\"))\n",
    "        rows1[\"voxel_num\"] = rows1.apply(\n",
    "            lambda row: convert_module_num_to_voxel_num(\n",
    "                row[\"module_num\"], row[\"subject\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        rows2[\"voxel_num\"] = rows2.apply(\n",
    "            lambda row: convert_module_num_to_voxel_num(\n",
    "                row[\"module_num\"], row[\"subject\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        stories_data_dict['voxel_num1'].append(rows1['voxel_num'])\n",
    "        stories_data_dict['voxel_num2'].append(rows2['voxel_num'])\n",
    "        stories_data_dict['expl1'].append(rows1['expl'])\n",
    "        stories_data_dict['expl2'].append(rows2['expl'])\n",
    "    else:\n",
    "        stories_data_dict['voxel_num1'].append([])\n",
    "        stories_data_dict['voxel_num2'].append([])\n",
    "        stories_data_dict['expl1'].append([])\n",
    "        stories_data_dict['expl2'].append([])\n",
    "\n",
    "\n",
    "joblib.dump(stories_data_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full df\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "# display(stories_data_dict['timing'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Margot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings['word'].values[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = join(sasc.config.RESULTS_DIR,\n",
    "                   'processed', \"pilot4_story_data.pkl\")\n",
    "stories_data_dict = joblib.load(output_file)\n",
    "stories_data_dict['rows'][0].to_csv('uts01_default_voxels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
