{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import sasc.generate_helper\n",
    "import sasc.viz\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from sasc.config import RESULTS_DIR, REPO_DIR, CACHE_DIR\n",
    "from typing import Tuple\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.append(join(REPO_DIR, \"notebooks_stories\", \"0_voxel_select\"))\n",
    "import pilot\n",
    "\n",
    "# set openai key\n",
    "import openai\n",
    "\n",
    "openai.api_key_path = \"/home/chansingh/.OPENAI_KEY\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select voxels\n",
    "Based on their similarity to predicted ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"UTS02\"\n",
    "cache_ngrams = joblib.load(join(CACHE_DIR, 'cache_ngrams', f'fmri_{subject}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = pilot.get_rows_voxels(subject=subject)\n",
    "\n",
    "# drop 7 voxels with worse performance\n",
    "worst_voxels = [368, 342, 248, 179, 155, 154, 168]\n",
    "rows = rows[~rows.module_num.isin(worst_voxels)]\n",
    "cache_ngrams_mod = cache_ngrams[:, rows.module_num.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correlations of every column with every other column\n",
    "corrs = np.corrcoef(cache_ngrams_mod, rowvar=False)\n",
    "\n",
    "# plt.imshow(corrs)\n",
    "# plt.yticks(np.arange(len(rows)), rows.expl.values)\n",
    "# plt.xticks(np.arange(len(rows)), rows.expl.values, rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(corrs)\n",
    "val = rows.expl + \" (\" + rows.module_num.astype(str) + \")\"\n",
    "df.columns = val\n",
    "df.index = val\n",
    "sns.heatmap(df, annot=True)\n",
    "# sns.clustermap(df, cmap='RdBu_r', center=0, figsize=(20, 20))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pairs = [\n",
    "    # related (>0.4)\n",
    "    (212, 171), # time, measurements\n",
    "\n",
    "    # medium (~0.2)\n",
    "    (339, 337), # physical injury or trauma, moments\n",
    "    (426, 442), # laughter, birthdays\n",
    "\n",
    "    # unrelated (< -0.3)\n",
    "    (122, 299), # locations, communication\n",
    "    (398, 79), # emotional expression, food preparation\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_one = rows.iloc[:2]\n",
    "expls_one = examples_one['expl'].values\n",
    "# examples_list_one = examples_one['top_ngrams_module_correct'].values\n",
    "examples_list_one = examples_one['top_ngrams_module_correct'].apply(lambda x: x[:3]).values\n",
    "\n",
    "examples_two = rows.iloc[2:4]\n",
    "expls_two = examples_two['expl'].values\n",
    "# examples_list_two = examples_two['top_ngrams_module_correct'].values\n",
    "examples_list_two = examples_two['top_ngrams_module_correct'].apply(lambda x: x[:3]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_list_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v0'\n",
    "prompts = sasc.generate_helper.get_prompts_interaction(\n",
    "    expls_one,\n",
    "    expls_two,\n",
    "    examples_list_one,\n",
    "    examples_list_two,\n",
    "    version=version,\n",
    ")\n",
    "\n",
    "PV = notebook_helper.get_prompt_templates(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = imodelsx.sasc.llm.get_paragraphs(\n",
    "    prompts,\n",
    "    checkpoint=\"gpt-4-0314\",\n",
    "    prefix_first=PV[\"prefix_first\"],\n",
    "    prefix_next=PV[\"prefix_next\"],\n",
    "    cache_dir=\"/home/chansingh/cache/llm_stories\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in paragraphs:\n",
    "    pprint(para)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
